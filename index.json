[{"content":" Download source code:\nhttps://github.com/challenai/wtfcache\nobserve our service # If we meet some performance issue, we need some information of our server to help us improve.\nTo know the current state of our servers, we need to collect some metric.\nIn another word, we need to collect some internal information of the server to expose metrics.\nThe count of keys, the size of our data, the count of requests, the delays, and something else,\nwe don\u0026rsquo;t collect too much information about our server since it\u0026rsquo;s a toturial,\nif you can collect 2 metrics, you can collect 200 metrics.\nhow to collect # we decide to count the keys and compute the total storage size as example.\nNo matter what interface and protocol we want to expose, the internal implementation should be the same.\nTherefore, we make the stat feature a shared one,\nin this case, we only collect cache metrics, so we place the metrics into cache folder directly.\nHowever, we should remember that we used sync.Map to replace internal hashmap to avoid thread unsafe issue,\nTherefore, we use atomic package to synchronise our statistics progress here.\n// stat.go type Stat struct { // entries count keys int64 // size of all the entries sz int64 } func (ms *Stat) CountKeys() int64 { return atomic.LoadInt64(\u0026amp;ms.keys) } func (ms *Stat) GetSz() int64 { return atomic.LoadInt64(\u0026amp;ms.sz) } func (ms *Stat) IncrKey(num int64) int64 { return atomic.AddInt64(\u0026amp;ms.keys, num) } func (ms *Stat) IncrSz(sz int64) int64 { return atomic.AddInt64(\u0026amp;ms.sz, sz) } update count when set and delete operation appears # When we set a key, there\u0026rsquo;re 2 cases: add or update.\nIf we meet an add operation, we need to add key count and size of entry.\nIf we meet an update operation, we need to compute the difference between the existed key and new one.\nFor a delete operation, it\u0026rsquo;s just check whether the key exists and decide whether we need to decrease count.\nfunc (mc *xxCache) Set(k string, v []byte) error { // test if the key exists. if !exist { mc.Stat.IncrKey(1) mc.Stat.IncrSz(int64(len(k) + len(v))) return nil } mc.Stat.IncrSz(int64(len(v) - len(v_.([]byte)))) // ... } However, no matter what case we program in our 2 modify operation, we can find there\u0026rsquo;s a race issue,\nFor example, if 2 requests to set a key arrived concurrently, the \u0026ldquo;check if the key exists\u0026rdquo; progress can get a true reply at the same time, and the key count would be unaccurate,\nThere are different methods to handle this problem.\nThe easiest one is to lock the critical area and try to make it sychronised.\nfunc Set() { mutex.Lock() defer mutex.Unlock() // ... if exist { // ... } } Since it\u0026rsquo;s a high performance cache application, the cost of a lock in hot code area is not acceptable,\nwe can use cas idea to store the original state, then we set the key if there\u0026rsquo;s no confliction, and retry if it conflicts.\n// positive lock func Set() { for { count := mc.Stat.CountKeys() // ... if exist { // ... } mc.Stat.CompareAndSetKeyCount(count, int64(len(v) - len(v_.([]byte)))) } } To make the toturial as understandable as possible, we don\u0026rsquo;t actually use and lock,\nHowever, in the real world, the application is not always correct, but runs as normal,\nand trade-off is some thing works here, to trade off between performance and accuracy of keys count, we choose to sacriface the accuracy of keys count,\nbecause it\u0026rsquo;s just a metrics, 12.64k keys and 12.63k keys are totally no difference, and this trade-off improve performance, make it easy to maintain too.\nAt last, we can provide a HTTP endpoint to show the metric.\n","date":"24 June 2024","externalUrl":null,"permalink":"/contribute/cache/wtfcache6/","section":"Code Space","summary":"If we meet some performance issue, we need some information of our server to help us improve.","title":"Build Cache from Scratch: 5. observe our service"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/tags/cache/","section":"Tags","summary":"","title":"cache"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/tags/code/","section":"Tags","summary":"","title":"code"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/tags/distributed-system/","section":"Tags","summary":"","title":"distributed system"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/","section":"Lun Jiang","summary":"","title":"Lun Jiang"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/tags/protocol/","section":"Tags","summary":"","title":"protocol"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/tags/storage/","section":"Tags","summary":"","title":"storage"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"24 June 2024","externalUrl":null,"permalink":"/series/wtf-cache/","section":"Series","summary":"","title":"wtf cache"},{"content":" Download source code:\nhttps://github.com/challenai/wtfcache\nExpose high performance TCP API for users # Different from HTTP protocol, we build TCP service from scratch without any framework,\nThe main reason is that the TCP only serves in the specific high performance case, the protocol is not actually standardized due to the consideration of performance.\nSince it\u0026rsquo;s a cache application, we can communicate with the client via redis compatible protocol, so that the redis client can talk to our application directly. By the way, It\u0026rsquo;s not difficult to design a new protocol for a special use case, but it\u0026rsquo;s unnecessary to repeat.\nThe current Redis protocol is called RESP V3 (Redis Serialization Protocol, Version 3).\nredis RESP V3 # Our cache application provides 3 interfaces: get/set/delete.\nTherefore we need to provide 3 commands according to RESP.\nThe set request should be SET mykey myvalue\\r\\n. The successful set response should be +OK\\r\\n.\nThe get request should be GET mykey\\r\\n. The successful get response should be $7\\r\\nmyvalue\\r\\n.\nThe delete request should be DEL mykey\\r\\n. The successful delete response should be +OK\\r\\n.\nThe failed response with error message should be -ERR xxx\\r\\n.\nbuild basic server # In the case of someone who hasn\u0026rsquo;t tried TCP programming and feels scared,\nactually, there are no magic inside a TCP connection, it\u0026rsquo;s pretty standard. If you program with C, you need to create a socket, bind socket to an address, listen and accept.\nHowever I will tell you it\u0026rsquo;s all bullshit, there are history reasons, the socket concept and all the details are inherited from system calls.\nThe program itself doesn\u0026rsquo;t provide any convenience compared with some modern languages like Rust, Go or node.js(2012).\nThe truth is that, in 99% cases, we create the servers with some template code even in C/C++,\nbecause most of the time we create the TCP server, not local unix domain socket server, it\u0026rsquo;s unnecessary to consider too much about hundreads of different parameters and error case,\nit\u0026rsquo;s all covered by language itself.\nIn golang, we need to listen to some addresses. And start accepting connections. It\u0026rsquo;s simple, but no performance loss because of the internal battery: epoll inside. And of course, less bugs.\n// step 1 server, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) // handle error // step 2 for { connection, err := server.Accept() // handle error } handle bytes according our protocol # We don\u0026rsquo;t have authorization for connections, therefore we can handle requests from the first bytes.\nThe protocol is line based, therefore we can create a buffer utils to read line and write line, read and write bytes.\ntype Buffer struct { w *bufio.Writer r *bufio.Reader } func (c *Buffer) ReadLine() (string, error) { // read line with standard library api line, err := c.r.ReadSlice(seperator) } func WriteLine(l string) { // write line with standard library api c.w.Write(l) } As a result, our TCP server could simply run as follows.\ntype Client struct { buf *buffer.Buffer } func (c *Client) Read() error { line, err := c.buf.ReadLine() switch start word of line: case \u0026#34;GET\u0026#34;: // handleGetRequst case \u0026#34;SET\u0026#34;: // handleSetRequst case \u0026#34;DEL\u0026#34;: // handleDelRequst default: // error } ","date":"23 June 2024","externalUrl":null,"permalink":"/contribute/cache/wtfcache5/","section":"Code Space","summary":"Different from HTTP protocol, we build TCP service from scratch without any framework","title":"Build Cache from Scratch: 5. TCP cache server"},{"content":" Download source code:\nhttps://github.com/challenai/wtfcache\nExpose popular HTTP API for users # There are different ways to expose HTTP API in golang, for example, the net/http, fasthttp, we can use some high level web framework to expose too: gin, martini, echo.\nThe fasthttp provides competitive performance when the throughput is higher, The web framework is much easier to use and maintain.\nIn this project, we employ the basic net/http from golang standard library. The only thing we need to to do is implement func Handle(w http.ResponseWriter, req *http.Request) in the case of standard library. Therefore, we can route our request as follows:\nfunc CacheRoute(w http.ResponseWriter, req *http.Request) { switch req.Method { case http.MethodGet: HandleGetKey(w, req) case http.MethodPost: HandleSetKey(w, req) case http.MethodDelete: HandleDelKey(w, req) default: HandleNotFound(w, req) } } func HandleGetKey(w http.ResponseWriter, req *http.Request) { // cache.Get(req.Path) } func HandleSetKey(w http.ResponseWriter, req *http.Request) { // cache.Set(req.Body.Key, req.Body.Value) } func HandleDelKey(w http.ResponseWriter, req *http.Request) { // cache.Del(req.Path) } func HandleNotFound(w http.ResponseWriter, req *http.Request) { // w.Write(\u0026#34;not found\u0026#34;) } now, we can bootstrap our http cache server to store keys in both memory and disk!\n","date":"17 June 2024","externalUrl":null,"permalink":"/contribute/cache/wtfcache4/","section":"Code Space","summary":"There are different ways to expose HTTP API in golang","title":"Build Cache from Scratch: 4. HTTP cache server"},{"content":" Download source code:\nhttps://github.com/challenai/wtfcache\nWhat is a cache, how to describe a cache # cache is somewhere we can store data. We usually find data by its ID, or key, thus we need to store a key-value pair when we store data. At last, we have the basic requirement of removing a specific key-value pair.\nAs a result, or cache should look like as follows:\ncache: - set(key, value) - get(key) -\u0026gt; value - delete(key) according to our design, we get the abstract interface.\ntype Cache interface { Get(key string) ([]byte, error) Set(key string, value []byte) error Del(key string) (bool, error) } We design our cache abstract in the cache folder.\nImplement the real internal structure: in memory # We find the structure of the cache looks like a hashmap,\nand the hashmap provides O(1) time complexity for all our operation: get/set/delete.\nTherefore, we decided to use hashmap to store our kv pairs.\nNotice that our design is to store data in a hashmap,\nand if there are some other considerations like performance, we can use some other data structure.\nBut there\u0026rsquo;s something we need to pay attention when we use hashmap,\nwe don\u0026rsquo;t expect our cache serve only one user at a time, it\u0026rsquo;s not good enough for current world,\nso our cache should handle more than one requests simutaneously, in another world, we need a thread-safe hashmap, so our choice is sync.Map.\nThe core implementation is showed as bellow:\ntype MemCache struct { sync.Map } func (mc *MemCache) Get(k string) ([]byte, error) { // sync.Map.Load(k) } func (mc *MemCache) Set(k string, v []byte) error { // sync.Map.LoadOrStore(k, v) } func (mc *MemCache) Del(k string) (bool, error) { // syc.Map.LoadAndDelete(k) } We implement our memory cache in the mem folder.\nImplement the real internal structure: disk oriented # to persist data to the disk, most of the time the database is the best choice,\nbecause there are quite a lot of different types of database which provide different features currently, it\u0026rsquo;s unnecessary to build a whole new one, and the internal structure is not really easy to understand. In our case, we need a key-value based database, there are different options like LevelDB, RocksDB, Riak, Cassandra, DynamoDB, BoltDB, BadgerDB. However, the critical feature for us is a tiny high performance single node storage engine. Thus the best option should be RocksDB, we don\u0026rsquo;t need distributed feature, we don\u0026rsquo;t have really huge data for a cache application, we hope it to be real-time, and we have a golang version RocksDB alternative which provide high performance, it\u0026rsquo;s called BadgerDB, and of the most value is that this engine is written in golang, it\u0026rsquo;s extremly easy to maintain, you can find everyone can run it with go run main.go, but with RocksDB, you don\u0026rsquo;t know how to maintain them properly since they have so many dependencies which you need to install munually, adn disastrous C++ code.\nThe core implementation is shown as below:\ntype Store struct { db *xxDB // for example, BadgerDB, or even mysql... } func (s *Store) Get(k string) ([]byte, error) { // db.Get(k) } func (s *Store) Set(k string, v []byte) error { // db.Set(k) } func (s *Store) Del(k string) (bool, error) { // db.Delete(k) } We implement our persisted cache in the store folder.\nImplement the real internal structure: cloud persisted # If you understand all the steps above, I believe it\u0026rsquo;s not difficult for you to bridge the interface to the cloud platform.\nTherefore it\u0026rsquo;s an extra task for you. If you need some assistance, feel free to email me.\n","date":"16 June 2024","externalUrl":null,"permalink":"/contribute/cache/wtfcache3/","section":"Code Space","summary":"cache is somewhere we can store data. We usually find data by its ID, or key","title":"Build Cache from Scratch: 3. Cache core implementation"},{"content":" Download source code:\nhttps://github.com/challenai/wtfcache\nintro # In this article, we will see how to build a distributed cache system from scratch, this is the first part of our articles.\nset the basic environment # First of all, let\u0026rsquo;s simply create a folder to store the new project, the command should look like this: mkdir cache.\nyou should start a new go project with go mod init something, for example: go mod init cacheme, then you can find a go.mod file that appears in your directory.\nSince we have a project, we can create a main.go file in our project to print hello, world:\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;vim-go\u0026#34;) } Now, it\u0026rsquo;s time to run the project with go run main.go, you can also compile it to a binary with go build -o hello main.go and input ./hello to run this binary executable file.\nthe other things we could do (but not necessary) are listed as follows:\nadd a .gitignore file so that we can ignore some useless files like .DS_Store in mac environment add a read me so that everyone else can understand what this project is used for. add a license, I personally prefer some simple licenses like MIT or GPL3 ","date":"16 June 2024","externalUrl":null,"permalink":"/contribute/cache/wtfcache2/","section":"Code Space","summary":"build a high performance cache from scratch.","title":"Build Cache from Scratch: 2. initialize project"},{"content":" Practice here:\nhttps://leetcode.com/challenai/\nintroduce # 类型 阶段 题号 题目 1 锁定 307 实现数组 update 和 sum(i, j) 2 待定 315 计算右侧小于当前元素的个数 3 锁定 75 012 三色 partition 4 锁定 373 两个升序数组，求最小的 k 对组合 5 锁定 208 实现字典树 5 待定 472 字符串数组，求组合词 B 锁定 102 B 锁定 297 二叉树正反序列化 B 130 淹没岛屿 B 133 clone 图 B 锁定 210 给定节点和边，完成拓扑排序 B 310 最小高度树 B 备选 463 岛屿周长 B 社区 871 加油站，求经过的最少加油站数 D 锁定 39 组合 D 40 可重复组合 D 锁定 46 排列 D 47 可重复排列 D 备选 216 选 k 个数字(0~9)，和为 n D 备选 377 组合的和为 k D 备选 491 枚举递增子序列 D 锁定 124 BT 路径和最大 无 D 备选 129 BT 根叶路径数字和 无 D 备选 79 单词搜索 D 备选 212 单词搜索 D 备选 91 数字解码成字母 D 锁定 126 单词列表，形成链条路径 D 127 单词列表，形成链条路径 D 494 数字列表，添加+-得到 n 7 锁定 2 链表和 D 待定 200 求 01 矩阵中岛屿数 P 待定 139 长词能否由词列表中词组成 D 待定 140 长词能否由词列表中词组成 8 锁定 53 求最大连续子数组和 8 锁定 209 寻找最短子数组，和大于 target 8 76 最小的覆盖串 8 锁定 220 是否存在距离小于 k 且差小于 t 8 锁定 239 求滑动窗口内的最大值 8 待定 424 求最长重复子串(aaaaaxy,2 个不同) 9 社区 42 条形图接雨水 9 锁定 16 3 数和最近 k 9 备选 11 或 42 接雨水 10 19 链表移除倒数 k 11 385 [123,[456,[789]]]解析成嵌套类 11 394 3[a2[c]]解码成accaccacc 12 锁定 23 合并 k 个排序链表 12 锁定 493 前面比后面大两倍的对叫翻转对 13 锁定 154 搜索重复翻转排序数组的最小值 13 29 实现除法 13 待定 34 搜索排序数组中数字的起始位置 13 74 在排序矩阵中搜索 n 13 社区 410 最小化最大值，值是和 13 锁定 378 行列升序矩阵，求第 k 小 13 驱逐 2035 数组平分，让两者和也尽可能相等 14 社区 435 求没有重叠区间的最小移除数 P 45 跳到最后最小步数 P 锁定 72 编辑距离 P 暂缓 85 01 矩阵找最大的矩形 P 社区 174 地牢游戏，加减血但不能死 P 锁定 312 扎气球，max 三数积的和 P 备选 64 最小路径和 P 社区 ?188 股票 5 题，No.4 P 社区 ?309 股票 5 题，No.5 P 社区 ?354 套娃信封的最大套娃数 P 社区 213 抢劫三题 2 P 社区 32 最长合法括号 P 锁定 300 LIS 问题 P 暂缓 221 01 矩阵找最大正方形 P 锁定 416 能否均分数组 P 锁定 132 串分割成回文子串 P 锁定 152 求子数组最大乘积 P 社区 ?376 求最长摆动子序列 P 社区 115 求 s 的子序列数，s==t P 驱逐 96 求 1~n 生成的 BST 数 P 社区 44 正则匹配单个和任意值 P 暂缓 741 路径上有 0,1,-999，求最大值 P 社区 1092 求最短公共母串 P 暂缓 1000 合石头，求合并最小代价 16 304 二维数字矩阵，求子矩阵和 16 363 求数字矩阵的最大子矩阵和 17 128 求数组中数字能组成的最长连续序列 17 锁定 432 设计 inc/dec/getMax/getMin 结构 18 94 中序遍历 18 110 求 BST 是否平衡 18 114 将 BT 展开成链表(链表是前序遍历序) 18 105 从前序和中序构造二叉树 18 257 打印所有根叶路径 18 锁定 236 LCA 问题 19 25 k 个一组翻转链表 19 锁定 146 实现容量为 k 的 LRU 缓存 19 148 归并排序链表 20 待定 402 给定数字字符串，移除 k 个数字，求最小 21 待定 215 求数组第 k 大 22 待定 287 1~n 的数组只有一个重复数字，求出来 99 166 42 接雨水 99 166 57 插入区间到无重叠的区间列表 99 166 64 矩阵路径最小值 99 166 73 有零的行列置零 99 166 80 移除重复的，保留最多 2 个 99 166 90 有重复子集 99 166 116 创建完全二叉树的横向指针 99 166 117 创建普通树的横向指针 99 166 120 三角形的根叶最短路 99 166 121 股票家族 1/6: 无限买卖 99 166 198 打劫家族 1/3: 数组打劫 99 166 211 实现前缀树，并实现 search(\u0026quot;.a.pl\u0026quot;) 99 166 220 是否存在距离 k 内，差在 t 内的两个 99 166 231 数字是否是 2 的 n 次方 99 166 241 加减乘除算式加括号，求所有可能结果 99 166 278 第一个错误版本 99 166 279 数字由 1,4,9,16 等组成，求最小组成数 99 166 309 股票家族 3/6: 1 天冷冻期 99 166 355 设计推特，实现 post,feed,follow 等 99 166 367 求一个数字是否是完全平方数 99 166 368 求数组最长整除子集 99 166 397 可以/2,+1,-1，求得到 1 的最小操作数 99 166 410 分割数组为 k 份，极小化最大值 99 166 450 从 BST 中删除一个值 99 166 473 给数组代表火柴棒，能不能搭成方块 99 166 474 给1,01,1101和 01 总个数，求子集数 99 166 486 预测赢家: 从左右拿,猜先拿会不会赢 99 166 523 是否存在子数组和为 k 的倍数 99 166 525 求 01 数组的最长 01 平衡子数组 ","date":"23 March 2023","externalUrl":null,"permalink":"/leetcod3/","section":"Lun Jiang","summary":"Practice here:\nhttps://leetcode.com/challenai/\nintroduce # 类型 阶段 题号 题目 1 锁定 307 实现数组 update 和 sum(i, j) 2 待定 315 计算右侧小于当前元素的个数 3 锁定 75 012 三色 partition 4 锁定 373 两个升序数组，求最小的 k 对组合 5 锁定 208 实现字典树 5 待定 472 字符串数组，求组合词 B 锁定 102 B 锁定 297 二叉树正反序列化 B 130 淹没岛屿 B 133 clone 图 B 锁定 210 给定节点和边，完成拓扑排序 B 310 最小高度树 B 备选 463 岛屿周长 B 社区 871 加油站，求经过的最少加油站数 D 锁定 39 组合 D 40 可重复组合 D 锁定 46 排列 D 47 可重复排列 D 备选 216 选 k 个数字(0~9)，和为 n D 备选 377 组合的和为 k D 备选 491 枚举递增子序列 D 锁定 124 BT 路径和最大 无 D 备选 129 BT 根叶路径数字和 无 D 备选 79 单词搜索 D 备选 212 单词搜索 D 备选 91 数字解码成字母 D 锁定 126 单词列表，形成链条路径 D 127 单词列表，形成链条路径 D 494 数字列表，添加+-得到 n 7 锁定 2 链表和 D 待定 200 求 01 矩阵中岛屿数 P 待定 139 长词能否由词列表中词组成 D 待定 140 长词能否由词列表中词组成 8 锁定 53 求最大连续子数组和 8 锁定 209 寻找最短子数组，和大于 target 8 76 最小的覆盖串 8 锁定 220 是否存在距离小于 k 且差小于 t 8 锁定 239 求滑动窗口内的最大值 8 待定 424 求最长重复子串(aaaaaxy,2 个不同) 9 社区 42 条形图接雨水 9 锁定 16 3 数和最近 k 9 备选 11 或 42 接雨水 10 19 链表移除倒数 k 11 385 [123,[456,[789]]]解析成嵌套类 11 394 3[a2[c]]解码成accaccacc 12 锁定 23 合并 k 个排序链表 12 锁定 493 前面比后面大两倍的对叫翻转对 13 锁定 154 搜索重复翻转排序数组的最小值 13 29 实现除法 13 待定 34 搜索排序数组中数字的起始位置 13 74 在排序矩阵中搜索 n 13 社区 410 最小化最大值，值是和 13 锁定 378 行列升序矩阵，求第 k 小 13 驱逐 2035 数组平分，让两者和也尽可能相等 14 社区 435 求没有重叠区间的最小移除数 P 45 跳到最后最小步数 P 锁定 72 编辑距离 P 暂缓 85 01 矩阵找最大的矩形 P 社区 174 地牢游戏，加减血但不能死 P 锁定 312 扎气球，max 三数积的和 P 备选 64 最小路径和 P 社区 ?","title":"algorithm questions list"},{"content":" Download source code:\nhttps://github.com/challenai/wtfcache\nBefore we start, we should figure out our final requirements and prepare the environment.\nprerequisite # editor like goland, vim or vscode. git go environment *nix environment introduce # purpose:\neasy to understand, step by step. no one left behind. build a runnable and high performance prototype. introduce the core concepts for storage application. provide runnable code for every step in the tutorial. features:\nprovide key-value read and write ability. expose popular HTTP restful API. expose redis like TCP interface for users. collect some runtime stats and metrics. keys expiration and eviction. unit and e2e test. support persistence, free from data loss. introduce transaction and its implementation. introduce some critical methods to improve and measure performance. introduce some STOA or cutting edge concepts. ","date":"18 March 2023","externalUrl":null,"permalink":"/contribute/cache/wtfcache1/","section":"Code Space","summary":"before we start, we should figure out our final requirements and prepare the environment.","title":"Build Cache from Scratch: 1. introduction"},{"content":"","date":"1 March 2023","externalUrl":null,"permalink":"/tags/economics/","section":"Tags","summary":"","title":"economics"},{"content":"","date":"1 March 2023","externalUrl":null,"permalink":"/series/economics/","section":"Series","summary":"","title":"economics"},{"content":" 参考: Perloff, Jeffrey M. Microeconomics, 8th Edition\n提醒一句，如果没兴趣，不想研究学术，那这些都是不必要的，取其神而忘其形，不要本末倒置。不要以为中级就比初级有价值很多。\n$$ $$ 前面我们讨论了需求一些细节，包括个体如何决策，也讨论了供给的一些细节包括生产如何发生，如何提高产出，如何定义成本。\n现在我们要尝试从数量上观察。\n企业主的利润表现为\n$$\\pi = R - C$$\nR 是 Revenue C 是 Cost pi 是 利润，至于为什么是 pi，主要是要装的高大上 说人话就是，到手的钱，减去成本，剩下来的就是利润\n生产函数表现为\n$$q = f(L, K)$$\nq 是产出, Output L 是 Labor K 是 Capital 说人话就是，产出和 劳动力，资本有关。也就是人越多，机器越多，弄出来的奶茶越多。实际上不一定越多，所以这里是个 f。\n短期生产函数表现为\n$$q = f(L, \\bar K)$$\nK 上面有个横线是指，他是 constant，被 fixed，不变的 说人话就是，短期内，厂房，机器是不会边的，变的是人工，你可以招更多人提高产量。他阐述了一种关系而非一个具体量，他是说招的人越多，生产的奶茶越多，而不是招两倍的人，就生产两倍或 3 倍的奶茶。\n边际产出表现为\n$$MP_{L} = {\\Delta q \\over \\Delta L}$$\nMP_L 是指 Margin Product 对 L 的关系 q 是 Output 产出 L 是 Labor 劳动力 说人话就是，增加的产出/增加的工人数，就是招更多的人能增加的产量，这种增量比例称为边际产量，他告诉你，你招更多人，产量能增加多少。比如奶茶店有 5 个人，你再招发现产量反而下降了，那他的边际产量是负的，也就是说，这种极端情况下完全就不应该再找人了。\n工人的平均产出表现为\n$$AP_{L} = {q \\over L}$$\nAP_L 是指 Average Product 对 Labor 的关系 从这里开始，我们稍微跳一点，给与读者思考空间。\n这个函数很简单，描述了一个事情，可能工人多了，平均产出反而上升了，又或者下降了。想象工人如果能以流水线方式生产，效率可能提升，然而就那么多机器，也不能 10 个人用一个机器，所以产出又开始降低。\n关于流水线的趣闻，笔者曾经去过苏州的代工厂的流水线体验过一天。流水线(pipeline)是通用的伟大创新，主要观点是分工导致专业化，专业化代表效率，如果我天天拧螺丝，那我可以成为拧螺丝最快的人，大家都是最快的从而导致整体效率提高。但是切身体验一把才知道，流水线对劳动力意味着什么。在经历了一个十分二百五的考试后(默写 26 个字母，23+43 等于多少)，我成功入职，我从有点兴奋到麻木，几个小时后我开始怀疑人生，我会想这样的生存形态究竟有什么意义，我甚至在想我不确定他们还能不能称为人类，他们就在那儿一直重复同一个动作，或者叫人形机器更合理一点。那种工作，没有挑战，没有未来，枯燥，你不能跑到楼下去买杯奶茶，实际上，甚至上厕所也要考虑时间。\n去厂里上班，工人们戏称为打螺丝，因为流动性比较强，所以换厂子叫提桶跑路，有些劳工还是挺乐观的，精神状态并没有我那么糟糕。他们主要的困境是，即使离开厂里也不知道干什么，没有学历，没有其他生产资料，很难找到好一点的工作，要么赚不到钱，要么去工地那种地方，他们有些人会考虑赚点的钱，也就是积累了足够的生产资料后，回去开个小店，以至于把他们当作梦想。从有些人的角度看，这听起来有点搞笑，比如我会想，如果开个小店免费送给我，我一定是不肯去的，一家店也没规模效应，上限实际是可以算出来的，对我来说，时间是值钱的，经济成本太高(机会成本等)。实际上，朋友会和我讲让我去和他开公司，我会想，小公司期望收益不一定有多高，也许有一天，会有老婆想要很多钱，多到变成一个数字，我会跑出去给她弄。另外一个角度，开店要啥子钱，对我来说，觉得有赚头借点钱就搞起来了，不想借就拉些人入伙，赚了一起分也好弄，你觉得一定能搞，可以借助杠杆去对赌，去和投钱的老板讲赚到一起分，算股权，亏了算借贷。有些人说这是不同的思维模式，我看来其实并不是，工人承担不了亏损，如果真的有心去开个店，这些都很容易想到，只是不敢这么干。也许根本就没有出路，某一天社会淘汰这种工种的时候，他们大概可以随社会进步而过上更好的生活，所以廉价劳动力或许是血腥的，从这里大概也能看出产业转移重要的原因。积极点，从另外一方面考虑，他们也还是幸福的，毕竟厂房是恒温的，吃喝是不用愁的，休息时还可以去网吧，还可以去自由恋爱。这比那个以科举和小农经济为代表的时代要好很多。\n这里倒不是觉得高厂里的工人一等，或者意在劝人好好学习，天天 up。而是想说，不要一天到晚廉价劳动力优势，确实我们有很多经济方法可以干预工人工资以提高一地的生产总值和竞争力，很多场景下也曾高瞻远瞩的这样实践过，可是那是一个群体的真实人生，要有同理心，也许那点微薄的收入真的意味着什么！如果我们每个人都抱着这样的想法，自己一定要做人上人，他们辛苦是因为他们没好好学习或者父母没钱又或者人比较笨，这是一种事不关己高高挂起的想法，如果这是一种群体文化，社会只会越来越糟糕。能读这部分的，说明不是笨蛋，我期望但我们随手在推导出数量关系后，即使发现不断延长工作时长而不是扩招能提高产量，也不要做这样的决策，就像这个小故事说的一样，那是一些人真实的人生。我见过很多聪明的利己者，那些最最顶尖大学的，或许能力不咋地，又或是确实颇有能力，但是利己水平却确实是一流的，这是竞争过载的表现，是文化和历史原因，不好责怪，但是我希望身居高位也要心怀悲悯，我知道有些人心里想的是，大部分人被卖了还会帮着数钱，但是你这么聪明在设计制度规则和政策的时候也请留一些生存空间，而不是假装看不见不知道，如果来这个世界是为了受罪，谁还来，谁还生？能力越大责任越大，不仅是面向老板或者领导，更是面向社会，我有意写在这里，是这个故事的一点私心，送给聪明的你。\n让我们综合上述，验证没有在填鸭子，而是真的理解了，\n请在 2 分钟内描述下面的图表含义。\n等产量曲线表现为\n$${\\bar q} = f(L, K)$$\nq 是 Output 产出，根据上述描述，是指 fixed L 是 Labor K 是 Captical 说人话就是，机器多点人少点，和人少点机器多点，可以得到一样的产出。美国在百年前实现了规模化的农业，使用飞机喷洒农药，使用 google 卫星地图看到美国中部地区那些圈圈不是什么军事基地而是农田，人类基本的农业方式笔者小时候刚好经历过，割水稻的时候，拿把镰刀一把一把割，一人几天的工作量等于一个联合收割机三十分钟的工作量，这就是这个曲线的含义，即产出可以在资本和劳动力组合间平衡。所以老一辈说粒粒皆辛苦是有真实含义的。\n等产量曲线是一种对长期产出的描述。\n技术替代的边际率形式是\n$$MRTS = {\\Delta K \\over \\Delta L}$$\nMRTS 是 marginal rate of technical substitution 这个曲线相当有意思也很有现实意义，他考察了固定输出的情况下，劳动力和资本的边际变化，说人话也就是，如果我不用人工割水稻而用收割机，我需要用多少钱来省下一个人。收割机可能相当于 1000000 个人，那么一个人的劳动力就等于收割机的钱/1000000\u0026hellip; 他以数量化的方法表达了如何了资本和人力如何置换，当然在这里他依然是不可用的，他只是一种简单的关系阐述，后面我们在讨论一些经济政策，在讨论对比生产效率时会用到这个方法。\n很容易的，我们可以推导出\n$${MP_{L} \\over MP_{K}} = MRTS$$\n这也就是为什么，技术替代的边际率沿着等产量曲线递减\n根据上面讲解的公式。做一些题目\n一个示例: Cobb-Douglas 产出函数是\n$$q = AL^{\\alpha}K^{\\beta}$$\n进而推导出\n$$MRTS = -{\\alpha \\over \\beta}{K \\over L}$$\n感兴趣可以自己推导一下，注意不要被 A, alpha, beta 吓到，他们都是常量。不同的产业可能会有不同的系数和指数。\n另一个示例: 阐述下面公式的含义\n$$f(2L, 2K) \u0026lt; 2f(L, K) = 2q$$\n很简单，就是 2 倍投入没得到 2 倍的产出，就是边际回报递减(术语 DRS)的数学表达。\n那么如果你没看出来，请表达出 IRS 和 CRS。\nTodo\n鉴于这些数量方法是所谓中级或高级经济学的内容。绝大部分人不需要。\n后面会用英语编写，以使他们更为朴素实用。\n","date":"1 March 2023","externalUrl":null,"permalink":"/inspiration/eco4quantity1/","section":"Grocery","summary":"取其神而忘其形。对弱者心怀悲悯，不作恶。","title":"economics: 4. 数量化"},{"content":"","date":"1 March 2023","externalUrl":null,"permalink":"/tags/inspiration/","section":"Tags","summary":"","title":"inspiration"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/availability/","section":"Tags","summary":"","title":"availability"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/consistency/","section":"Tags","summary":"","title":"consistency"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/fault-tolerant/","section":"Tags","summary":"","title":"fault tolerant"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/paper/","section":"Tags","summary":"","title":"paper"},{"content":" Original: \u0026ldquo;Spanner: Google’s Globally-Distributed Database\u0026rdquo;\nAuthors: James C. Corbett, Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher Frost, JJ Furman, Sanjay Ghemawat, Andrey Gubarev, Christopher Heiser, Peter Hochschild, Wilson Hsieh, Sebastian Kanthak, Eugene Kogan, Hongyi Li, Alexander Lloyd, Sergey Melnik, David Mwaura, David Nagle, Sean Quinlan, Rajesh Rao, Lindsay Rolig, Yasushi Saito, Michal Szymaniak, Christopher Taylor, Ruth Wang, Dale Woodford (Google, Inc.)\nintroduce # Spanner is a database. It\u0026rsquo;s distributed across the world.\nSpanner provides a SQL interface, extends some function for placement,\nwhat we called placement is which data should have how many replicas and where to deploy this data so that the users(database clients) are close to the data source geographically. we called it geographic locality.\nSpanner provides global availability, because the data is replicated across the world to prevent the potential disaster for a specific place. The data of Spanner can be rebalanced automatically for better workload performance tuning and nodes changes.\nMy interest is Spanner has a high performance transaction even in global level. The average delay from Europe to U.S. should be more than 100ms and a bit more for some Asian country like Japan. The generic transaction provides atomic updates and lock free read-only transaction, which is the critical part to improve transaction overall performance because for most of the applications, the read operation should be much more than write operation. The r/w ratio could usually be 10 ~ 1k.\nThe internal basic data distribution model is some paxos groups which hold some data range(which is defined as directory) replicas, the number of replicas could be 1, 3, 5 or even more, which depends on application requirements and could be adjust dynamically.\nwhat it looks like # A spanner instance is called a universe.\nIncludes some zones, it\u0026rsquo;s basically a abstract like a data center, but for application level for isolation, the real data center can contains more than 1 zones. In addition to the zones, there are 1 universe master and 1 placement driver. The universe master is a plain and simple dashboard. The placement driver is responsible for replicas modification(data migration), balance load.\nA zone includes a zone master as the manager to distribute data, a proxy, and a spanserver. The spanserver is the core component for the system, it provides transaction and replication, it\u0026rsquo;s basically some paxos groups, the transaction coordinators is embed in the paxos groups to improve availability of coordinators. The basic implementation of concurrency control is 2 phase lock, a lock table is introduced to store the lock state. The leaders of the paxos groups work as the replication consensus makers, and as participants for coordinators. The different replication leaders elect new leaders as coordinator leaders, (I guess, but the paper doesn\u0026rsquo;t point out explicitly, in the last 2 sentence in paper 2.1), and the result is a 2 phase commit implementation for multi shards/directories transaction.\n","date":"28 February 2023","externalUrl":null,"permalink":"/paper/spanner/","section":"Papers","summary":"Spanner is a globally distributed database. It provides SQL interface and relational like schema. It provides transaction feature for its scale and inspires some successors like cockroachdb and tidb","title":"Paper: Spanner as a Global Scale Database"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/replication-group/","section":"Tags","summary":"","title":"replication group"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/sql/","section":"Tags","summary":"","title":"SQL"},{"content":"","date":"28 February 2023","externalUrl":null,"permalink":"/tags/transaction/","section":"Tags","summary":"","title":"transaction"},{"content":" 参考: Perloff, Jeffrey M. Microeconomics, 8th Edition\n提示： 对于没有接触过经济学的朋友，应该去打开某个教科书或课程，当发现某些地方看不懂的时候，再回到这里，当然，如果你不打算进行深入研究，只想看个大概，那也就当个小说刷下知乎。对于自认为很行的朋友，尤其是所谓科班出身，也很值得一读，汉语文化里，所谓的学校教学，不过尔尔，大部分课程和书籍讲的云里雾里，倒也不一定是故意不教你，而是老师自己是否掌握也不好说。\n兼容并蓄，和而不同。取长补短是一种很好成长方法。\n微观 # 微观经济学是关于个体的讨论，是真实的经济。\n宏观经济学是对整体的讨论，观察到的是统计，是表象。\n我们观察一个人的生活。\n需求 # 每天要吃饭坐车穿衣睡觉，可能某些人的习惯是早上一杯咖啡，有些人是晚上一杯酒，一杯奶茶，\n这些东西都是买回来的，是我们想要的东西，于是大家总结了下，统称为需求。有需求是因为我们想要活着，活的舒服，活的安全，我们可以加很多形容词，比如安全，我们是指不用担心未来丢掉工作，不用担心股价下跌，实际上，需求并不总是一成不变的，一些现象和文化确实导致了需求的变化。有一些对需求有正向驱动，有一些则有负向驱动，比如经济发展期的消费主义对需求有正向驱动，而经济衰退期的躺平文化，则冲击了需求。需求是根本性的经济组成，我们可以观察到一些失败的经济体失败的部分原因是需求过低，这和我们传统意义上的认知的刚好相反，我们总是期望从外部赚更多钱，我们观察作为管理者如何受这种文化影响而做出失败的经济干预，降低了经济的活力。例如外向型经济通常因内部需求过低导致的严重经济问题。\n关于需求我们有很多可以讨论的地方，之后我们联系其他因素，以一种关联视角回过来再看需求。\n供给 # 有这样的需求其实是因为有相应供给，如果没有奶茶，我们就不需要奶茶，如果没有咖啡，我们就不需要咖啡，我们没有对星际飞船的需求是因为，没有星际飞船。有什么，统称为供给。听起来反直觉，但是原始人确实没有智能手机的需求，而受过高等教育的人可能对外语的电影有需求。\n经济学家号称经世济民，并不关心奶茶，所以就有需求和供给这样的说法，尽管是微观，他们考虑的仍是整体情况，或者是从抽象的角度。通过类似这样的抽象方法，我们可以通过较为简化的模型，去理解复杂的过程。这类似于物理中对任何物理都抽象为质点来观察其运动。\n量 # 奶茶店要预先准备椰果，波霸，红茶，准备多少是个问题，准备的多了，放到第二天变质了就浪费了，准备的少了不够卖就等于亏钱了，准备了多少杯，是供给数量。观察到，如果奶茶店多了，奶茶就会降价，这里指新品会降价，从而避免竞争带来的顾客损失，也就是说，通过降价可以吸引顾客，原来奶茶喝的少的，甚至不喝的人，也会跑过来买，这就意味着需求量上升了，这是一种普遍存在的现象，作为一种经验(术语叫 Law of Demand)被广泛认知，不仅仅是奶茶。\n相对应的，供给因价格下跌而减少，奶茶价格低就不好赚钱，赚不到钱导致很多奶茶店倒闭转行，从而缩小了供应数量。\n以上则是关于供应，需求，价格的关系，诚然，工资，个人偏好等一系列因素会影响供应和需求，但是我们主要关注价格，口味偏好作为个体差异，在市场上通常被统计结果掩盖，市场经济的一个特征是自由的交换，卖东西的时候，不管你是谁，你有钱我就给你，与集权的古代社会不一样，或许只有某些人可以使用丝绸，某些人可以坐马车，因此个人偏好没有任何实际意义。当然我们观察 kfc 这样跨文化的产品集合时，口味偏好产生出重要影响。\n供给量和需求量都随价格变动，一个价格越高，供给越多，一个价格越高，需求越少，刚好是相反的，\n供给和需求达成一致: 均衡 # 相反的两个曲线，必然有交叉点，那是恰到好处的平衡点，意味着供给和需求达到某种妥协，在这里，可以 deal(成交)。这个点的术语叫均衡(market equilibrium)。术语本身没有什么价值，他是个符号，重要的是理解+这样类似的符号背后的意义，+就像是左手三个豆子，右手两个，放一起了。那么均衡呢。对于想要谈资的，应试的，工作的，术语非常重要，基本代表一切，对于想要工作出色的，创造性的，认知世界的，搞清楚发生了什么则更为重要，记住均衡并不能给你的公司带来更多收益，但是理解交叉点的含义却可以。因此，除了极其重要的术语，大部分术语不做介绍。\n现实世界中这个点总是变来变去，那是因为奶茶的成分可能是植脂末，原材料豆子的市场价可能会因收成不好提高，居民的工资也可能因经济不景气而下降，比如最近(2022~2023)发生的情况，消费主义作为一种经济和文化现象开始降温，像喜茶这样的企业未雨绸缪的大幅度降低了新品价格区间，企业倾向于收缩规模以削减成本，事实上除了早期正常的调整外，实际的经济状况可能比大部分人想象的要稍微糟糕一些。这些话题相对敏感，主要原因可能要许多年以后才能讨论。总之，像这样的因素导致了供给和需求的曲线上下移动，最终均衡点一直在移动。这些曲线在教科书上可能表现为两条直线，实际上，并没有一个线性的\n均衡点的移动并没有任何问题，实际上，绝大部分市场并没有位于这个交叉点，这个点通常来讲意味着效率，买家卖家都满意的一个折中位置，如果市场受到干预，则效率会被降低，干预通常由政策制定者进行，这通常是经济政策失败的原因之一。\n关于经济学是否可靠 # 我知道有很多人认为，经济学并不可靠，很多现象不能用所学知识解释。实际上，绝大部分现象完全解释的通的，发展中国家的很多市场不是完全竞争市场，甚至很多市场是寡头垄断的，这种垄断不来源于竞争，政策影响了很多东西，甚至包括供给，尽管理论上供给控制并不是一个财政或货币工具，滥用导致很多经济问题，假如我们把群体总效用(所有参与经济的 utility，不知道这个词是不是这样翻译)作为指标，实际上这些政策总是损害均摊效用，用个不恰当的比喻，这些政策使全体居民平均变得不幸，当然，厉害的各有各的厉害之处(有靠卖铁卖铜，有靠旅游的，有靠金融的，总之五花八门)，弱鸡的都一个样，越是经济和制度建设落后的国家，腐败，内幕交易，失败政策越多，这不独独哪一家是这样，程度不同而已。个人认为这是发展仍处于某种阶段的必然结果。当我们把这些都联系起来，可以解释很多看起来玄幻的现象。当然，另一部分让人觉得不可靠的原因是，模型不对，主要由于考虑的因素不够或者一些基本的方法没有掌握。\n接着讲奶茶，\n这里有一些有趣的点，比如一个地方奶茶店过少但是有对应的需求，那么就有可能产生比较高的价格，现实世界中，奶茶是标品，价格统一，实际上会导致销量上升，奶茶店也会获得超额利润。由此产生了过剩或短缺的情况，供应太多，就过剩了，价格开始下跌，观察中东石油欧佩克组织，是一个联合石油供应源以减少供应(是指你家地底下埋着石油，我家也是，我们都卖，但是我希望我们不要恶心竞争，石油供应太多卖成矿泉水的价格我们日子都不好过，所以我们要联合起来)，以提高价格，但是价格并不是可以随意提高，如果价格过高，石油需求方则会加速寻找替代品，比如煤矿，风能，水能，电能，从而导致石油出现永久性的需求下降，一旦寻找到价格更低的能源，资本对新能源的研发投入会增加，技术落地最终导致石油的价格变得可能连矿泉水都不如。\n实际上，这个简单得模型出奇得有效，从直觉上讲，奶茶也好，手机也好，都有需求和供应，我们可以描述当手机供应上升时，手机的变动。遗憾的是，这一个单一的模型并不能解释很多东西，比如苹果和三星建立了新的产线，但是新手机价格依然上涨了，这也就是很多人为什么觉得经济学不可靠。实际上经济学确实有其问题，但是通常情况下，如果解释不了是因为模型弄的不对，考虑的变量不对。例如假设石油由一国控制输出，那么实际上他拥有有限的定价权，如果你想要，他说多少钱，你只要愿意接受，那就是多少钱，因为他可以随意改变供应数量，这种情况称为垄断，实际上是一种严重危害整体生产能力的情况，意味着石油并不一定算是属于人类，即使假设石油是无限的，输出国依然会控制输出量，如果不控制，那么输出国就是一个荒漠中的几个矿井，如果加以控制，那么输出国就是沙漠中成片的城市，这取决于石油在人类生产中的价值，这是经济中不公平的一面，或者是市场经济中不公平的一面，但是如果我们讨论诸如命令经济之类的模型，也就是通过计划分配，会发现基于人类自己计划的方案简直完全没有公平可言，尽管没有实现之前，往往可以有很美好的幻象，但是实际结果缺失一塌糊涂，有句话可以很好的形容，始于最崇高的理想，止于最低级的欲望。现在仍然有很多人心存幻想，但是有些事情虽然没人再提及，但是确实尝试过，群体的苦难是实验的代价，不管是哪个群体，那段时间都是黑色的。实际上，我们可以通过某些方式修补市场经济，所谓市场经济，就是自由交换的经济，我可以生产任何东西，卖给任何人。我们不考虑大麻这样的东西，实际上是因为他是成瘾品，这样的交换通常是不公平的，就像是强行把水变成了高价的商品，成为一种强制性的依赖，区别是，这种类型的水其实我不应该有需求，而电力则截然不同，电力生产是否应该被控制是个有趣而无趣的问题。后面我们会重点讨论类似大麻这部分话题，实际上是一种市场失败的表现，市场不是万能的，但是现实情况往往是，我们远远低估了市场的力量，高估了人工的力量。\n价格在干吗 # 之所以提及市场经济这个词，是因为我们想要理解价格发挥的作用，实际上价格正在进行分配，当我需要什么，我就会得到什么，我努力一点，通常可以多得到一些我想要的，通过价格。 价格有趣的地方在于，他是客观的，没有价格的体系里，我在别人家当保洁，我去扫完厕所，主人说嘿小老弟你干的不错，我的 24k 纯金马桶锃光瓦亮，明天早上就多分你两个馒头，可是我这么努力并不是为了多吃俩馒头，我觉得不公平，我比做饭的老王拿的少，谁能说打扫厕所要拿到的应该比厨师少呢，事实上，每次吃馒头时，喜欢拍马屁搞事情的老李每次都拿的比我俩多，哎！向我这样专业勤奋的厕所清洁工竟然得不到应有的回报。因为主人有自己的看法，他的看法可能是主观的，甚至受自己的亲属朋友关系，言语的影响，现实世界中他做分配一定是很不公平的，不公的分配会影响生产，导致即使我这样优秀的厕所清洁工也会怠工，这也就是命令式的经济总是会走向灭亡的实际原因，之所以说会走向灭亡，是因为他会先败光之前的小农经济或市场经济的家底，这是现在没有一个经济超过平均水平的国家实质上实现命令式经济的原因，因为走向过毁灭，现在在喘息。我不清楚朝鲜是否实行计划经济，但是有不少地方历史上曾实施过，比如委内瑞拉，南非，俄罗斯，越南。我认为研究计划经济没有任何意义，所以之后不做讨论，但是我们依然会讨论其他可能的经济模型，比如畅想基于合成专家系统的经济，即使用人工构建的智能体实现分配以代替市场，或者某种形式的混合经济模型，以解决朴素市场中经济周期或者市场失灵这样的问题。\n关于干预 # 通常来讲，可怕的并不是管理者对私利的渴求，而是无知和无能。\n实际上，在关于管制和干预方面，\n我打算进行大量的案例讨论，以观察失败和成功的货币财政政策带来的影响，\n这并不针对谁，考虑到现实世界，即使是美国和日本这样经济最为出色的国度里(我们会讨论日本经济的问题，或许读者并不认为日本经济是否足够出色)，依然存在很多失败的经济政策，我们也会讨论某国大量失败的经济政策，和一些成功的策略，及其影响。\n竞技游戏里通常有句嘲讽的话，说，就是栓条狗在键盘上都打的比你好，决策者并不总是想我们想象中那么明智。\n之所以更多聚焦在失败的经济政策上，是因为经济政策通常是二元的，做或不做，栓条狗是玩不了游戏的，所以栓条狗来做我们的决策者或许在很多情况下真的比政策制定者更优秀，通常经济学家比较倾向于自由市场。我们会在理解完一些经济概念，思想和过程的情况后，了解一些各个经济学派的差别，其中甚至有一些奇葩的异类。\n通常来讲，失败的经济政策通常情况下是政策制定者无能，实际上，也有很多其他因素，例如制定者内部也不是铁板一块，内部利益团体角力失败或占据主导会影响政策结果。这里我们只关心经济策略及其影响，不关心他们为什么最终指定了这样的政策。\n和正常的教科书，课程顺序不一样，我们先不讨论经济干预。我们先讨论市场，完全排除外部干预的影响，原因是，现代经济，所有经济很有活力的地方，都是市场经济。即便是卖资源为生的地方。\n弹性 # 似乎价格是供给和需求的晴雨表，个体会对价格做出反应，实质上，大家的反应并不一致。\n观察大米这种农产品，因为我们每天都要吃米，即使大米价格暴涨至双倍，恐怕我们也难以拒绝大米，大米暴涨会导致社会冲突，但是绝不会大幅度降低需求，这和我们的生活习惯和历史文化有关，大米是一种主食，而房子，豪车这样的东西暴涨则会严重影响需求，如果一套房子从 200 万涨到 300 万，需求可能大幅度降低，因为受教育程度较高原因，这种现象在发达国家尤其明显。这也意味着大米的需求某种程度上缺乏弹性，他就像个石头一样，你价格再变动，他和房子相比几乎岿然不动，这是另一个广泛存在的现象，术语叫弹性(elasticity)，本质上讲的是需求和供给相对于价格的敏感程度。弹性的意义在于，如果价格发生变化，供给方和需求方对此的反应可能是不一样的，考虑到降价 20%带来的影响，大米可能加工厂亏损严重，而豪车因销量上升而获得更多收益，实际上，利用弹性可以做很多有趣的事情，很自然的我们想到，像大米这样的商品，需求缺少弹性，意味着需求方对涨价没有太好的办法，只能默默承受，倘若大米不能涨价，是不是可以让一些其他商品涨价呢，对于某些特定商品，是否可以变动其弹性呢，如我们所说，豪车富有弹性，如果我们想办法降低豪车的弹性再趁机抬价，是不是可以获得更高的收益呢。\n这里对应于书的第 45 页，Price elasticity of demand/supply，后面讨论了税收的影响，我们不谈这个，因为之前讲过，我们先不讨论干预，税收作为一种广泛存在的干预，我们最后集中讨论。\n结语 # 以上，便是基本经济原理的全部了，它包含需求和供给，中间通过价格作为桥梁紧密联系，但是价格对需求和供给的影响并不固定和稳定，使用弹性来描述。\n接下来，我们对需求，供给，价格进行一一观察，研究他们的细节。 最后我们在动态视角上观察他们如何交互。如果会编码，我们甚至可以利用 python 脚本编写一些模拟程序，来观察动态过程，当然结果可能是一堆数字在波动，没有那么形象。\n本系列禁止转载\n","date":"25 February 2023","externalUrl":null,"permalink":"/inspiration/eco2basic/","section":"Grocery","summary":"市场不是万能的，但是现实情况往往是，我们远远低估了市场的力量，高估了人工的力量。","title":"economics: 2. 需求和供给"},{"content":" 什么是经济 # 经济大概是很多人都好奇的，感兴趣的东西，\n经济是一组交换，交换是因为匮乏，经济是一种知识，经验和实践。\n我们人类偶然间发现了一种可以用来提高平均生活水平的组织生产的方式，于是将这个经验系统化，对这种组织生产的方式的各个领域进行研究拓展，进一步形成了一些新的经验，从而进一步提高了生活水平，这些经验的集合称为经济学，对应的实践相当成功，叫做经济，相应的各个领域称为产业经济学，劳动经济学，城市经济学，金融经济学，其实就是对上班发工资研究一下，就称为劳动经济学，对后来出现的借贷现象研究一下，就称为金融经济学。\n我们之所以有现在的物质生活水平，主要不是因为理解了某种科技，而是因为交换，被仔细研究的经济，指导了人类进行疯狂的自私的生产追求，导致每个人生活水平提高。通过将每个人提供的平均价值最大化，促进整体的价值最大化。\n相信对于很多人，主要的驱动力来自于对学术的神秘感和对财富的渴望，\n因此，我想分享我对经济的一些见解，理解大规模交换的过程。\n我保证这些文章都能读懂，如果读不懂，那就是一坨废话，我想，废话有其作用，我们的一生产出过大量废话，为了完成某个指标的废话论文，为了完成任务的某些心得，某些体会，高中无病呻吟的作文，废话有其作用，但是我们不想弄成这样。\n根本原因是我可以为了点赞曝光广告，为了某个人交代的任务制造一坨垃圾，但是记录自己的认知时，不会应付了事。现在我想要 open 一点，所以放出来。\n总体目标 # 封面是 Wolf of Wall Street 里 Matthew 的一句话: \u0026ldquo;Fuck the clients, No!\u0026rdquo; 剧情是，主角刚进华尔街，相当于一个卖股票的地方(这种机构一般叫证券公司，实际上可能卖一大堆东西，保险，债券(就是借条)，还有些故弄玄虚的组合产品，通常被称为衍生品)，得到一个厉害前辈的欣赏，主角表现得很拘谨，说了一通这样的银行家真了不起呀，希望帮那些商业大客户好好赚钱(可以想象成进了最近很火的那个月薪 8 万的证券公司，然后自己分到角色不是研究员，而是大客户经理的实习生，然后你就和前辈说，我一定努力给马云，麻花腾，玉柱好好赚钱)，为客户好好赚钱，然而电影里 Matthew 用讽刺的方式以前辈的口吻告诉主角，fuck the clients，意思是去 TM 的客户吧，我们不关心马云赚不赚钱，No，我们根本不关心! 我们要做的，就是把钱从他的口袋里拿出来，装进我的口袋，done，结束了，这就是全部，就这么简单。 Matthew 不关心是因为，电影里的世界确实是这么运行的，他的理解是正确的，深入的，但反直觉的，他的方法是简洁的，高效的。\n所以主角作为他的精神和方法论继承者取得了巨大的成功。至于实际世界 broker 怎么运行，关不关心客户赚不赚，我们漠不关心，因为他只是个 broker，我们着重于研究这些证券如何对资源配置，并不关心作为中介他能赚多少钱，分红是多少。也不关心这些客户盈亏，但是考虑一些特别主题的时候，比如行为金融，我们确实可能会关心一下，也就是说我们只关心经济是怎么转起来的，真正的情况是什么。 既然写到这里，作为开篇，也可以提两句，实际上我个人对此毫不关心。\n我期望我们建立对经济深刻的理解，如 Matthew 对兜售证券的理解一样深刻，他不是一些用来吹嘘的谈资，也不是写文章用些术语来装高大上的套话，而是知道事情如何发生，走向何方，甚至以某种方式定量分析，以便相对精准的观察，思考和验证。\n我的背景和计划 # 大概是 6,7 年前大学的时候，我仔细研究过宏观和微观经济学，金融市场，机构，产品和衍生品。\n当时年少，一无所知，探索的过程中发现，宏观经济学里 GDP，通货膨胀，CPI，金融模型，货币供给，\n这些词一个个听起来都很厉害，颇有指点江山的意味，所以着重研究了宏观经济学。\n如果重来一次，我会选择重点研究微观经济学，并且不会研究像投行，金融市场这样的知识，他们是信息和形式，并不是原理，尽管他们确实听起来很高大上，这一点上我颇有点后悔。\n所以我打算从微观经济学开始，重温一些基本的原理和过程，并记录下来，\n至于一些宏观，金融和一些分支，我并不打算回去再看，尤其是宏观经济学。\n可能如果发现有好的信息经济学，能源经济学相关的书或者课，我会跟一下。\n这个过程不是高密度的学习，实际上，自从离开大学后，我已经很少读经济学相关的课本了。 但是阅读了许多经济评论一类的东西，也每年都会写3 ~ 5篇自己的理解，主题通常是兴趣产生的，后面有个附录包括了兴趣点，我自己称之为研究性探索，就是以兴趣为起点进行严肃的讨论，给出一份简短结果作为报告。然后那次搞丢了所有数据，照片，代码笔记，啥都没了，就给一锅端了，也是我开始开放所有东西的开端。 已有的主题包括，印象最深的是10~20年期上海房价分析，是18年左右给身边人做的，最后结论是房价不会上涨了，按照通货膨胀水平上下浮动，主要的观点是这个行业及其上下游行业在经济部门占用较高的比重，因为发展中国家必然趋向于发达国家导致的增长率会逐年降低，带来的下行压力导致我们的决策者政策趋向于期望平缓，但是下行会降低消费者预期，结果就是房价涨不上去了，但是通过控制供给，强制再分配这类干预，依然可以扭曲价格体系。当时涨的不行，我却看跌，同时建议在意的人不要买房，后来一想开心就好了，随他去吧，结果今天房价比预测的数据中要糟糕一些，或许是受当时环境的影响，又或许是无能。 也包括日本失去的三十年原因分析这样的主题，一来可能但是读了某个日本经济的书，感兴趣然后自己研究了下，也可能就纯粹兴趣。\n接下来我仍然打算这么做，唯一不同可能是把他们都分享出去。 另外可能看一些书。也会记下来，通常以年记得，工作了没那么多时间集中看书，关键也是，应该边看边想，而不是囫囵吞枣。\n我有很多自己的见解，并不意在写出来换取流量，而是自己的个人笔记和观点， 可能有些不会公开，我也在不断尝试说服自己不要想着对这些通用的东西有藏私的想法，这有一个过程。人总是这样，或许一个介绍一样的东西，发了也就发了，但是自己认为正确的有价值的思考，怎么舍得分享呢，或许厉害的人看这些文章觉得可笑，一文不值，但是自己觉得好的，总是不愿意分享，这和代码一样，往往最高质量的代码，是开源的，但是我们依然藏着掖着。\n到目前为止，一点存货都没有，是因为之前的所有笔记都搞丢了，也算是个契机。\n关于内容 # 我会讨论一些相对显得非常特别的经济体，比如日本，比如美国，比如英国。\n或许因教育原因有些读者并不知道，日本是亚洲第一个崛起的国家，当时的生产规模，生产效率都与其他各地不能同日而语，是旧世界的当之无愧的王者，他是那样的鹤立鸡群，说鹤立鸡群也怕是委屈他了，考虑到生产力在市场化分配的地域很大程度上代表了生活水平，以至于我们不禁要问，到底发生了什么才有那么高的物质生活水平，是他们比我们聪明，勤劳，还是人口众多，资源丰富？又或是真的受到了很多他国的扶持，或者像有些人说的那样是抢来的？昔日的荣光变成今日的瓦砾，那些光辉岁月终将流逝，日本衰败了吗，从比较的角度来看，日本经济确实不如从前，我们如何定义衰退？日本 GDP 排名为何逐渐下降。迈向死亡是痛苦的，政策制定者如何处理经济事务？他们如何看待自己的经济状况并不重要，重要的是，他们做了什么，他们能做什么，在这里，我们不观察他的心情，观点，我们考察他们的实践和结果。实际上，他们的过往是动人的，那种拼搏，从挣扎到无力不禁使人落泪，人类的一些根本的情绪是共通的，我们会大概的梳理一下历程，却不去过多关心细节。\n英国发生过著名的工业革命，考虑到现代经济农业所占比重并不高，反而后面才出现的所谓工业占有很大比重，我们不禁想知道，工业到底是什么，是炼铁还是制造汽车，既然发生了工业革命，那么他们经济又发生了什么，工业如何影响生产能力，工业对旧时代有没有影响，也就是工业对农业又没有影响。\n美国是一个很有趣的国家，从经济，文化角度，他有太多太多值得讨论的地方，在此不做赘述。但是后面会大量和主要讨论，原因是，他是成功的，独特的。\n诚然他们都是经济超级大国，但是从经济角度看，他们又显得和他国格格不入，是，他们是不一样的。我们会评价他们某些时间节点的经济和金融政策，或者你稍微学过点，要指正说是货币和财政政策，这些政策比如经济危机中，作为一地的决策者，他们有什么工具可以调整经济，尝试干预的后果是什么，是扬汤止沸，釜底抽薪抑或是隔靴搔痒，甚至是抱薪救火，这听起来像个笑话，你可能不信，但是抱薪救火确实是大量存在的情况，他们很有趣，你搞懂了你也会笑，你会问，这 TM 都是些什么鬼，实际上，制度相对落后的地方，决策者往往倾向于掩盖错误，这无可厚非，但是经济不以个人意志转移，经济可不关心决策者的面子。经济决策通常是一个复杂过程，要考虑的不仅是效率，同时像是公平，内部利益团体的博弈，信息不对称和传播的失真都会导致一些看似愚蠢的经济决策。\n同时也会讨论一些相对落后的经济体，比如印度和某国。\n为了避免你可能会觉得我专门嘲笑某国来的，我打算先严肃批评反对以及羞辱嘲笑邪恶的西方国家的失败的经济决策，特别是我个人颇有好感的日本，和人人讨厌的坏蛋美国。然后仅仅作为一种反思，我们讨论我们是不是也存在错误，他们带来了什么影响。\n除了宏观上，我也会讨论一些每个人都感兴趣的事情，比如什么是财富，是房子，车子，还是现金，财富如何影响生活和社会。 研究这些不是我对成为富翁感兴趣，而是我对财富流动，积累这样的现象感兴趣，相比财富，我更对做出好的产品，理解现象背后的原因感兴趣。对于这些现象比如财富是如何大量获得，以至于从消费的角度看，财富完全变成了一个数字，因为不管怎么消费，数字都不会改变。说是讨论，其实是我个人观点，记录。\n之后我们对一些重要的场景，进行建模，以一种简化的方式观察事情如何发生，运行，走向何方，进行相对精确的描述，我们用一些数字描述，方面对误差进行度量，这样我们才能知道我们的理解在何种程度上是正确的，比如用我们的所知道的知识对某个公司进行估值，尝试猜测他可能的价格范围，然后和现实世界进行对比，观察偏差。又比如使用公开信息对一地经济趋势进行预测，尝试预测某次宽松政策影响下的宏观经济指标，因为缺少数据，我们很可能难以对一地经济进行精确讨论，但是趋势却是很容易预测，我们在拿到结果后进行复盘，以观察修正我们的模型和理解。宏观和微观是两个截然不同的方向，一个代表统计和整体意义上的情况，一个代表个体情况。\n我们甚至可以制定政策以应对突发事件，并比对真实的决策者如何处理问题，就结果对双方进行比较和评价。当然，时下的事情，往往只能私下处理，不适合放到台面上讨论，或许十年二十年后，才可以讨论。比如我们可以评价改革开放的影响，确立市场经济占所谓主导地位的影响。\n遗憾的是，过去熟悉的一些概念可能渐渐模糊，毕竟 78 年过去了，这样，我们也是边学边走。当然，科目一可能忘记，但是开车忘不了，读者不用担心，同时我也希望读者学会开车，而不是科目一二三四。\n做事情，要有这样的态度，即不畏权威，敢于质疑，勇于挑战复杂环境和问题，这倒不是让你和谁对着干，或者对前辈领导温顺谦恭，而是认识到其实有些人也不过就那样，比如你可看看你熟悉领域的那些个硕士博士论文，你就知道大家是个什么水平。总之不要以为别人就一定是对的，去挑战，去独自思考和解决复杂场景，去验证结果。\n理解一些原理有助于对现实世界进行建模，抽象，有助于理解现实世界究竟发生了什么，\n最后，我想讨论一些最新的论文，观点，研究成果，我们看看当前在某个具体的领域，我们对于某些特定领域的细节如何认知(通常来讲，论文描述的是某些细节问题)。\n除了回顾微观经济学之类的基本原理，其他大部分文章可能使用英文，虽然我确实想就自己的所思所想变得 open 一点，但我也确实没有义务和动机去照顾读者。\n另外，所有的文章并不具有术语和定义上的准确性，是我自己的看法。也并不为读者缩写，通常是我自己写完想法，学习笔记，然后略微润色一下，推出去。\n比如 经济是一组交换，交换是因为匮乏，经济是一种知识，经验和实践。\n我期望我学的，我想的，都是面向解决真实世界的问题而做，并不也永远不追求百科上那些精准的定义。同时对所有应试漠不关心，但是正在运行中的世界便是最好的考场，你的预测应该贴近现实世界的结果。\n2023.03.18: 后面读来这里显得有些傲慢，主要原因是这样的， 比如学过一些金融基础的人，可能会说债券那不是什么借条，是一种固定收益类金融产品，或者更精准也不能完全称为固收，因为固收描述的是确定收入，但是部分固收类收入并不确定。又或者现代金融早就不是简单的借条了。可是在这里的文章里他就是借条，实际上当你搞了几年搞清楚后会发现，他们穿着光鲜的皮，皮下就是借条(只是我浅薄的理解)，甚至整个光怪陆离的金融系统的本质就是借贷和买卖，所以核心是信用，借东西就是要信用，没有信用谁敢借。这是我的理解，我可不管他实际是啥。我唯一关心的是，我准你不准，或者你干脆不会更别提准不准，也就是大部分学经济学的人的真实状况，我能从财报读到论文，从利率预测到定价估算，估算从产品定价估到资产定价，资产从股票到保险。实际情况是，不是背几个概念就能搞懂利率或者财报，实际上，不管是看懂什么还是预测什么，他们是现实存在的问题，都需要你搞懂他们是怎么转起来的，也是我对自己的目标。 当然财报的知识我不会聊，也不会像微观经济学一样再去回顾细节，只会直接讨论某公司的情况。我的意思是，不能本末倒置了，学成了废物，就像大多数一样。我知道这里大概率读者是个会写代码的，但是大学教的系统，网络，算法有几个能入门的，经济也是一样的，大部分人不过是背诵了 socket 是啥，调度算法是啥，有什么特性，你让他用起来，那是不行的，更别提造一个。我再问一句更扎心的，有一个入门的嘛，可能真有，就是这个算法。那个是要搞比赛的。实际上经济学教育也存在同样的问题，学计算机的平均智力水平一定是高于经济学的。这种现象普遍存在。 当然，会所谓读财报并不是什么厉害的事情，我告诉你你也会了，实际也没啥屌用。真正厉害的是准，发现问题，比如乐视暴雷前，某老师从财报中看出问题，并公开发表。又比如次贷危机前某印度小哥的衍生品是否给金融系统引入额外风险论文(如果你读过教科书，学的还不错应该能记得衍生品本来的功能是什么？恰恰是对冲风险)。乐视高管知道吗，当然知道，所以他讲出来没啥大不了，别人能从披露信息看出来，那是厉害的。次贷分割包装的产品的创造者知道吗，当然算过风险，不算怎么敢卖，敢卖吗？卖，坏！他自己良心发现讲出来没什么，别人能在一篇叫好声中示警，那是厉害的。一群精英，决策者，甚至经济学奖得主说好，你说不好，那需要勇气，也需要能力。\n我关注什么东西 # 基本经济规律 资产定价 干预和政策 周期和经济危机 某几个特定行业的市场，包括云计算行业，石油和电力能源行业 企业总体经营状况，从财务角度，通常不会深入到行业细节。所以不会深入 增长，生产率相关问题 定量分析(不是那种统计和预测的量化分析) 竞争和垄断现象，放在一起主要是我觉得大多数市场竞争的结果必然是垄断，没太想清楚。 我不会关心具体产品竞争战略，也就是不关心怎么赢，只关心竞争导致什么结果。对供给和经济福利有什么影响。 暂时不太关心:\n机构，金融机构，监管机构 货币现象，比如货币供给，通胀 国际贸易，汇率 各种制度 利率，准备金，央行。不会集中讨论，除非讨论政策和干预时 财务和企业经营细节，如资本成本 理财 补充提醒，不要被这里误导，这里是笔者个人的偏好，\n一些我不太关心的东西确实非常重要，比如利率会实际的影响经济表现，导致资本流入流出，不是说他不重要。\n一些我关心的东西，确实没那么重要，比如周期，生产效率，远没有利率，准备金的概念重要。实际上生产效率只是一个非常细节的分支主题，他对个人完全没用。金融公司的人可能经常谈利率，但几乎不会谈生产，因为利率是影响短期市场表现的重要因素和调节工具。\n如果追求实用，学习一些基本理财而非各种理论会给你带来一些真正财富上的收益，当然野心大一点也可能是负收益，因为赌徒心理期望短期收益，实际上市场建设的并不像每股那样完善，同时还有考虑政策的影响，但是也有些低风险低收益的理财产品，这需要一些基本知识。总之会更实用一些。相反，可能会觉得有些文章是一些废话，比如美国对日本提供大量军需订单在短期内极大刺激了工业发展，实际对生活一点用都没有，好像是废话。\n结语 # 最后我也有一些善意的警告，\n雨中电闪雷鸣看的真切，却少了些美，美来自距离，是神秘感。\n所以搞懂，理解深入不见得是件好事，\n人生是一场痛苦的旅程，而认知，尽管在物质方面虽回报颇丰，但在精神方面，是彻彻底底的痛苦，\n做一个天真的孩子，未尝不是一件好事，一旦长大，就已经截断了退路。\n","date":"24 February 2023","externalUrl":null,"permalink":"/inspiration/eco1start/","section":"Grocery","summary":"搞懂一些东西不见得是件好事，人生是一场痛苦的旅程，而认知，尽管在物质方面虽回报颇丰，但在精神方面，是彻彻底底的痛苦，做一个天真的孩子，未尝不是一件好事，一旦长大，就已经截断了退路。","title":"economics: 1. 背景"},{"content":"Hi, it\u0026rsquo;s Lun Jiang from Shanghai.\n","date":"22 February 2023","externalUrl":null,"permalink":"/about/","section":"Lun Jiang","summary":"Hi, it\u0026rsquo;s Lun Jiang from Shanghai.","title":"About me"},{"content":"","date":"16 February 2023","externalUrl":null,"permalink":"/tags/disk/","section":"Tags","summary":"","title":"disk"},{"content":"","date":"16 February 2023","externalUrl":null,"permalink":"/tags/open-source/","section":"Tags","summary":"","title":"open source"},{"content":"","date":"16 February 2023","externalUrl":null,"permalink":"/tags/page/","section":"Tags","summary":"","title":"page"},{"content":"Todo: work in progress.\ndisk oriented # What a storage system provides, is interacting with disk. That\u0026rsquo;s the system we called database, store, block or small file store, log, persist queue. The disk is a block device, so the most efficient way to interact with disk is read/write a certain length of bytes, that means don\u0026rsquo;t read a byte, a bit, read more at a time. The specific length is usually 4KB, 8KB, 16KB, it depends on disk property and usage of our upper layer system. But no matter what size it is, we called it a page. The page could be fixed length, or not. Experience shows that fix length means indexable, for example, in http2 protocol, the frame header are 9 bytes, it\u0026rsquo;s convenient to parse, it\u0026rsquo;s much easier to skip to the specific content with a certain offset. You can image if you skip 1 byte, that is the package size, if you skip 3 byte, it\u0026rsquo;s the package type, if you skip 6 bytes, it\u0026rsquo;s the package checksum.\nTherefore, the disk basically split into pages for an application. As the basic storage unit, we fill content to the pages, it could be a tuple for RDB, a log entry for write ahead log, a offset number for B+ tree node, or a simple chunk for a file, even a plain blob.\nMost of the time, we design the page as self-contained, that says a page contains some meta information about itself, like the page size, page type, page id, but just in most of the case. I talk about it because I think it as a kind of primitive to construct storage system, if we master the principles, we can design and implement a storage system for a specific use.\nLet\u0026rsquo;s talk more about pages. The pages are usually indexed by directory, which records all the page positions and page data ranges, for example, the page No.23 is stored at position 42312 or position #5, it\u0026rsquo;s range is apple ~ application. But Not all the page content are sequential, it could be arranged by hash. Think about the mysql database, it provides B+ tree index and hash index. The main difference is sequential structure provides ability to range scan, but hash index could be faster. Using a directory to index the page is called page heap.\nTo track a page in directory, we need record the content of the page and whether the page is empty.\ntransaction # implementation: innodb # implementation: leveldb # graph LR A(user) -- put/get --\u003e B(leveldb) B --\u003e C(memtable) B --\u003e D(sstable) B --\u003e E(write ahead log) D --\u003e F(disk) implementation: boltdb # implementation: badgerdb # ","date":"16 February 2023","externalUrl":null,"permalink":"/contribute/storage/","section":"Code Space","summary":"work in progress","title":"Storage Engine: from Primitives to Implementation"},{"content":"","date":"16 February 2023","externalUrl":null,"permalink":"/tags/consensus/","section":"Tags","summary":"","title":"consensus"},{"content":" Original: \u0026ldquo;In Search of an Understandable Consensus Algorithm (Extended Version)\u0026rdquo;\nAuthors: Diego Ongaro and John Ousterhout (Stanford University)\nintroduce # Raft is a consensus algorithm widely used in industry. Another widely used available algorithm is called paxos, but the original paper \u0026lsquo;paxos made simple\u0026rsquo; doesn\u0026rsquo;t provide enough details about how to handle stream replication problem(replicate state machine), it talks about the single decree problem which is mainly about how to decide a certain value among a couple of nodes. The real applied algorithm is called multi-paxos, however, the nature of multi paxos in my opinion is almost the same with raft, the main difference is in leader election.\nbackground # We want to copy a stream to 3~5 nodes(which we called RSM, replicate state machine problem).\nThe critical point is all the nodes should keep the same sequence, that means same data unit, same order. For example, think about a stream of number 51348, every node should persist the same sequence 51348, 53148 and 51148 is wrong.\nAccording to some experience from building practical real world paxos application, we find multi paxos need to elect a leader to improve performance(limit the Round Trip of replication to 1). Diego catch up a great idea: why not split the leader election, the real replicate progress as different parts to make it much clear? That\u0026rsquo;s raft, a practical version of multi paxos, which the author declare more understandable.\nThe result is fault tolerant, which can tolerate less than half of the nodes fails. So every time we accept a request, we don\u0026rsquo;t need to copy to all the nodes, we just replicate to majority of nodes and response immediately to improve performance.\nhow to reach consensus # First of all, which we called leader, primary, master is exactly the same thing.\nWhen we want to replicate a stream, it\u0026rsquo;s always difficult to figure out how to reach a consensus for all the nodes in a specific issue, the problem is a stream includes a sequence of issues, that means a sequence of consensus need to be deal with, which sounds like a mess.\nHowever, if we have a leader, life becomes easier: all the nodes just follow the leader, replicate the stream element one by one according to leader, no coordination at all, if majority of follower nodes get the replica successfully, this replication turn has finished. An potential problem is the slow leader could become the bottleneck, which is a problem of raft.\nbut where is our leader # Let\u0026rsquo;s elect, everyone nominate himself as a leader, to make it more understandable, we called it president, everyone wants to be president, they all know the current term, for example, the current president is Baiden, the term is 47, in brief is Baiden is the 47th US president. If I want to be the next president, I will be the 48th president, so I nominate myself as 48th president, and someone like me is called the candidate. There is something to decide who can be the next president, in reality, it\u0026rsquo;s the speech, in raft, it\u0026rsquo;s who has more valid stream elements. Since it\u0026rsquo;s a stream replicate system, we compare the length of streams in all the nodes, the longest one should be the leader, so we compared last log index, if the log index is 6, it should longer than log with index 5. In the other hand, for every term, we have only 1 president, a president could be 47th, 48th, but 47th president could not be Trump and Baiden. So we compare the president term at the same time. if a node has term 48 logs, it should has newer logs than a node has only term 20 logs. In conclusion, every node try to be the president, but only one of them could be the next president. they will tell the others his expect term and his last log information, the log info includes log index and the term. The node who has the latest log, will become the next president with his expected term. Since the leader replicate the data to majority of nodes, the candidate only need to win the majority of the nodes instead all the nodes to be chosen.\nhow leader works # The president broadcast all request to the other nodes with its own term and the global sequential number, every log element has a term and an index number. In the real world, a president can propose a new act with his term and the act number, for every term there is only one president, which ensure if the term and index is the same, the log element could be the same, because a president could not say his 38th act is A, and his 38th act is also B. Notice that we could have more than president at the same time, but we have exact 1 president in the same term. If half of the nodes persist a specific element and response president, the president will say, ok, the act 38 starts work now, it\u0026rsquo;s a consensus.\nwhat if the leader fails # If the president dies, maybe a terrorist assault, a well-known scandal or a traffic accident, the other nodes would not get acts from president any more, they could not even hear the president, which we called \u0026rsquo;lose the heartbeat\u0026rsquo;, they would join the election, nominate themselves. However, how about the log sequence? The next president will find some nodes(like original leader) has longer log than him, some nodes has shorter log than him, but since he can become the leader, he must has all log which has become a consensus(accept by majority), so nothing lost if the president just handle new request and ignore the longer nodes. The president try to cover all the newer logs in the nodes which has longer logs, and fill the the nodes which has shorter logs. No matter how the original log sequence it looks like, every node would have the same log sequence with leader. That\u0026rsquo;s what we called strong leadership. But wait a minute, if the president cover the longer node, will something be lost? No, since the president could become a president, it must hold the logs commit before, in reality, the longer logs includes the elements haven\u0026rsquo;t reach a consensus. But if the president contains some log elements which haven\u0026rsquo;t commit, it will still replicate this elements left.\nLet\u0026rsquo;s think about a 1 node application, if we issue a write request, the node could shutdown before persist the write or after the persist, but the client don\u0026rsquo;t know, the client don\u0026rsquo;t get the response, so it feel like the write operation fails. Since the president in a 3 nodes system hasn\u0026rsquo;t response the client yet, if could have persisted the write or not, thus the president can cover the other longer nodes, and submit the log elements which even haven\u0026rsquo;t commit.\nthe whole progress # At the very beginning, we have some nodes, they all want to be the president to handle the out world request, if they have a president, they act like single one node, act as a whole. the system will keep running, if minority of the nodes fail, nothing lost, nothing broken in the perspective of out world request.\nIn order to be a president, the node need to propose his next term, if current president is 48th, and the node propose 42th, that means the node fall behind, the other node will refuse him. The node need to compare his latest log with the others too, because it\u0026rsquo;s a stream replicate system, we want the log to be highly reliable, nothing lost. If the node has newer log against the majority of the nodes, it could be voted as the next president. The reason of majority is we want to tolerate less than half of the nodes fail, and that also need the president replicate the data to a majority of nodes to promise the data will always survive.\nThe president broadcast log elements with their president term and log index, the log index is just like the index of an array to provide a sequence number. The president force all the other nodes keep the same log with him, and that\u0026rsquo;s how they reach consensus.\nIf a new president occurs, it would find himself has longer logs than some nodes, or has shorter los than some nodes too. However, it always try to make the other nodes persist the same logs with him, if the other nodes have different logs, cover them. The method to compare a specific log element is the term and sequential number, if term and N.O. is the same, the log must be the same, because a president will never say act 123 is A and act 123 is B at the same time, and there is only 1 president in every certain term.\ntry to read the paper before read the article, if you feel blocked, get back here instead of reading the article without reading the paper.\na visible progress of raft could be found here: raftThe Raft Consensus Algorithm\n","date":"16 February 2023","externalUrl":null,"permalink":"/paper/raft/","section":"Papers","summary":"Replicate is a common topic in distributed system, algorithms like paxos and its variants are difficult to understand, lack of details, but raft can help","title":"Paper: Raft Consensus Algorithm"},{"content":"","date":"16 February 2023","externalUrl":null,"permalink":"/tags/raft/","section":"Tags","summary":"","title":"raft"},{"content":"","date":"16 February 2023","externalUrl":null,"permalink":"/tags/replicate/","section":"Tags","summary":"","title":"replicate"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/cloud-native/","section":"Tags","summary":"","title":"cloud native"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/control-plane/","section":"Tags","summary":"","title":"control plane"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/controller/","section":"Tags","summary":"","title":"controller"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/etcd/","section":"Tags","summary":"","title":"etcd"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"kubernetes"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/series/kubernetes/","section":"Series","summary":"","title":"kubernetes"},{"content":" introduce # ","date":"13 February 2023","externalUrl":null,"permalink":"/contribute/kube/apiserver/","section":"Code Space","summary":"placeholder","title":"Kubernetes: API Server"},{"content":" Deployment # Deployment controller is used to specify replicas, rollback,\nthe keyword of deployment is scale.\nreplicas: the numbers of replicas MinReadySeconds: min seconds to get Ready Template: PodTemplateSpec... Paused: is this deployment paused... RevisionHistoryLimit: revision stack size limit, will keep given size history ProgressDeadlineSeconds: the deadline of this disployment, (still run while time out, but given condition, reason: ProgressDeadlineExceeded) Strategy: 更新时的策略，包括滚动和替换(recreate)，下面包含两个滚动更新的平滑策略。 MaxUnavailable: 缩容时，最大一次砍掉多少个 pod 或百分比。 MaxSurge: 扩容时，最大一次扩容的百分比或绝对数量。 Service # Service is used to expose Deployment and Stateful resource.\nFor example, there are 3 replicas of user service, the product service will issue RPC calls to user service, it can request service name directly. Use label to point out the real working Pod in a Service.\nSelector: 选择器，可以通过 label 来选取后面要暴露的 Deployment 或 Pod。 Ports: 一个 需要映射的端口列表 Protocol: TCP 或 UDP，都支持 Port: 服务端口 TargetPort: 后面那个 Pod 或 Deployment 的实际端口。 Ingress # Expose the cluster internal Pod to outside network like a gateway.\nRules: 代理规则 Job # Run job with container.\nCompletions: 代表几个 Pod 成功算整个任务成功 Parallelism: 并行度，是指同时允许的 Pod 数 PodFailurePolicy: Pod 退出码和状态(PodScheduled/Initialized等)不同时，如何响应(比如设置为失败) ActiveDeadlineSeconds: 任务最长能运行多久 BackoffLimit: 最大重试次数，默认6次 BackoffLimitPerIndex: 索引模式下，每个 index 的最大重试次数 MaxFailedIndexes: 一个任务被切成了几个索引，多少个索引失败了，就算整个任务失败。 TTLSecondsAfterFinished: 完成后的TTL，用于任务的自动清理，或说自动垃圾回收 CompletionMode: 可以是索引模式和普通模式，索引模式会把 Pod 建立0~n的编号，写在 Pod 名字上 Suspend: 是否正在休眠 PodReplacementPolicy: 当 Pod 处于 terminating 状态时，是否不等待，直接建立新的 ReplicaSet # Scale a specific Pod to n replicas.\nreplicas: 副本数 MinReadySeconds: 达到 Ready 状态的最小秒数 # TODO: 暂时没想到用处 Template: PodTemplateSpec... DaemonSet # Tell you container keep running, if it crarshed, launch it in place,\nusually work as a process/resource monitor, log collector.\nMinReadySeconds: 达到 Ready 状态的最小秒数 # TODO: 暂时没想到用处 Template: PodTemplateSpec... RevisionHistoryLimit: 回滚栈大小。历史记录保留的长度 UpdateStrategy: 更新时的策略，包括滚动和等待用户手动删除(onDelete)，下面包含两个滚动更新的平滑策略。 MaxUnavailable: 缩容时，最大一次砍掉多少个 pod 或百分比。虽然没有副本集，但是有多个节点，所以依然有百分比。 MaxSurge: 扩容时，最大一次扩容的百分比或绝对数量。 ","date":"13 February 2023","externalUrl":null,"permalink":"/contribute/kube/controller/","section":"Code Space","summary":"Deployment controller is used to specify replicas, rollback","title":"Kubernetes: Controller"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/message-queue/","section":"Tags","summary":"","title":"message queue"},{"content":" Original: \u0026ldquo;The Design of a Practical System for Fault-Tolerant Virtual Machines\u0026rdquo;\nAuthors: Daniel J. Scales, Mike Nelson, and Ganesh Venkitachalam (VMware, Inc{scales,mnelson,ganesh}@vmware.com)\nintroduce # This paper (virtual machine fault tolerant) I think is one of the best paper for someone who wants to step into distributed system. It provides some basic opinions about how to replicate state.\nbackground # The background of this paper is to design a fault tolerant virtual machine service, and the most common idea for fault tolerant is to replicate, so they talk about how to replicate computation.\nIf these terminology sounds a bit scare, like what the f**k they are? can you just say something more understandable like what a human can figure out, don\u0026rsquo;t worry, it\u0026rsquo;s really easy, assume you have a windows os, you don\u0026rsquo;t want it to stop running while losing power connection or want it to survive even from an earthquake. so you just run 2 windows in different computers simultaneously. Now we have 2 running windows os, if one of them stops, the other one will still keep running, thus our excel application can survive, however, we want these 2 windows run the same excel, handle the same row, the critical part becomes how to synchronize the state between 2 windows, the problem is what we called replicated state machine.\nThe nature is how to replicate state sequence, and the result is a fault tolerant computation system.\nwhat we have # We have 2 instances(virtual machines, image it as windows).\nOne called primary, the other one called backup.\nThey are connected via network, they shared a net disk.\nwhat to replicate # But the first problem is what to replicate?\nthe sequence of the current result. include the registers, memory bytes, and all what we have modified. That\u0026rsquo;s not a good idea, because the data is too large. the sequence of the operation. like we clicked some place. The real operation is the underlying instructions in the execution stack I guess. It doesn\u0026rsquo;t matter if our interests is just try to understand the replication instead of virtual machine. A terrible thing is operating system has some uncertain events like time and IO interrupt, as the result, this uncertain things need to be translated to certain things. They have a professional terminology called deterministic state machine to describe this uncertain operation, a common example is now function, assume you want to replicate the data between 2 database, set and get operation is certain, but now system call is uncertain. how to replicate (which called protocol) # The whole progress looks like this:\nThe clients send requests to the primary,\nprimary translate it to a couple of certain operations,\nprimary send it to the backup,\nbackup responds ack,\nprimary execute the request and response client,\ndone.\nWe have some problems here,\nThe first one is what if primary runs really fast, the backup falls behind a lot. sounds like after the primary respond, the backup found it will take him 2 days to catch up with the primary, that means if our primary stops running, we will lose our recent 2 days work!\nThe idea is to create a fixed length buffer to store the operations. We can assume the buffer can store 1 minutes work at most, if it\u0026rsquo;s full, the primary should pause and wait the backup to catch up with him. it\u0026rsquo;s like a block queue in inter process communication or a fixed length channel instance in golang. The purpose is to synchronize the speed of both sides.\nAnother problem is what if primary fails. If some machine fails, fault tolerant design starts work.\nIf the backup stops, everything seems still work, we fallback to the common scene: we have only one computer, it runs windows, it works.\nIf the primary stops, we want to shift to backup, but first, how does the backup recognize the primary has stopped. Just build a heartbeat to sense each other. If the primary find no heartbeat from backup, it can create a new backup. If the backup find no heartbeat, it try to become the primary, and repeat the behavior of the primary.\nThe progress of becoming a primary is usually called election in some consensus algorithm, vmft use a simple method to elect, use a cas(compare and set/swap) operation to write to a shared net disk. The winner of election is called primary, leader, master, main\u0026hellip;\nBy the way, to discover to the broken nodes in a system,\nwe use heartbeat,\nif we have only 2 nodes, they can heartbeat each other,\nif we have 3 or 5 nodes for a certain usage, we can create full connection among them,\nif we have unknown numbers of nodes, we can create a third party monitor service to probe all of the nodes.\ncompare with other system # GFS:\nvmft uses a more underlying model to replicate, it directly replicate the virtual machine, it theoretically means it can replicate all application run in the virtual machine like excel, database, game, but noticed that it must runs in low performance too.\nGFS is used to replicate bytes block specifically, that means it replicate in the application level. however, it provides no consistency promise while vmft says it will return only the primary and the backup persist successfully.\nThat means the data stored in GFS could be not the same at all, but application runs in vmft will always keep the same.\nsomething else # There are bunch of things we don\u0026rsquo;t care about, like the virtual machines specific improvement. Our interest focus on the general replication.\nReplicate the computation is not a good idea in some ways. because computation itself is expensive and it takes a lot of resources include not only the CPU, but also expensive memory, IO bandwidth. Calculate separately and replicate the result of a short period would be more competitive.\n","date":"13 February 2023","externalUrl":null,"permalink":"/paper/vmft/","section":"Papers","summary":"replicate computation is complex, paper vmft try to introduce the work to replicate virtual machine","title":"Paper: Virtual Machine Fault Tolerant"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/partition/","section":"Tags","summary":"","title":"partition"},{"content":" introduce # Nats includes two parts,\na simple memory queue with a TCP interface,\npersistence and at least once delivery.\nNats looks special in topology.\nNats nodes are connected fully with each other in a single cluster, thus the connections become a full mesh. It employ a gossip algorithm to probe the others. Every time a new node joins, it will register itself to the adjacent nodes. With the rumor pass by, the cluster internal nodes will know the newcomer. The meta information registered contains not only the address, but also consumers connected with this node. That means everyone in the network can dynamically know all the other nodes together with all the consumers, topics subscribed.\nHowever, the connections of full mesh does not increase linearly, so a cluster can\u0026rsquo;t include too many nodes.\ntodo\n","date":"13 February 2023","externalUrl":null,"permalink":"/contribute/nats/","section":"Code Space","summary":"Message Queue is a separate server to store message with FIFO sequence. Nats is a high performance message queue written in golang, it introduces some interesting ideas like connectivity, edge","title":"Queue: Nats, Connectivity and Edge"},{"content":"","date":"13 February 2023","externalUrl":null,"permalink":"/tags/replication/","section":"Tags","summary":"","title":"replication"},{"content":" introduce # Scheduler 从一组 nodes 中，选择最合适的 node，运行 pod.\n考虑的点有 affinity，taints，resource，os 等\nScheduler 的工作分为两步，\nfilter + score\n(predicate + priority)\n从 API server 监听 pod 事件，\n通过 Informer filter 已经有 nodeName 的节点。\n只响应 add 请求。\n通过 syncHandler 模式，ProcessNextItem(pod *Pod) . 处理的过程是 filter+score，\n首先调用一个一个 filter 函数，比如 filter 资源不符合的，volume 不符合的，taint 不符合的等等。\n然后对剩下的 nodes，按照 resouce 等打分。\n最后选最高分的 node，bind(pod, node)\n这里要先驱逐 node 上面的 pod 以支持 preempt，\n并为 pod reserve 资源，相当于对 node 的部分资源加锁。\n实际上 kubernetes 抽象出了一个新的 framework， 来将调度过程插件化了\n包括 pod 排序(QueueSort)，过滤前，过滤，过滤后(用于过滤后一个没有时抢占)，打分前，打分，合并总分，预定节点(reserve)，许可(permit)，绑定前，绑定，绑定后。\n整个主要是，过滤，打分和绑定，整个过程变得超级复杂。\n其中第一步的 pod 排序，为 pod 调度设置了优先级，哪个 pod 优先被调度。\nschedule 框架 kep 提案\n","date":"12 February 2023","externalUrl":null,"permalink":"/contribute/kube/scheduler/","section":"Code Space","summary":"Scheduler 在 affinity，taints，resource，os 的基础上，从一组 nodes 中，选择最合适的 node，运行 pod","title":"Kubernetes: Scheduler"},{"content":"","date":"12 February 2023","externalUrl":null,"permalink":"/tags/policy/","section":"Tags","summary":"","title":"policy"},{"content":"","date":"12 February 2023","externalUrl":null,"permalink":"/tags/scheduler/","section":"Tags","summary":"","title":"scheduler"},{"content":"Code in an Understandable way.\n","date":"13 June 2022","externalUrl":null,"permalink":"/contribute/","section":"Code Space","summary":"Code in an Understandable way.","title":"Code Space"},{"content":"Inspiration, Opinions, Experience, Art\u0026hellip;\n","date":"13 June 2022","externalUrl":null,"permalink":"/inspiration/","section":"Grocery","summary":"Inspiration, Opinions, Experience, Art\u0026hellip;","title":"Grocery"},{"content":"Make it easy, for human.\n","date":"13 June 2022","externalUrl":null,"permalink":"/paper/","section":"Papers","summary":"Make it easy, for human.","title":"Papers"},{"content":"","date":"22 October 2021","externalUrl":null,"permalink":"/tags/algorithm/","section":"Tags","summary":"","title":"algorithm"},{"content":"","date":"22 October 2021","externalUrl":null,"permalink":"/tags/interview/","section":"Tags","summary":"","title":"interview"},{"content":"","date":"22 October 2021","externalUrl":null,"permalink":"/tags/parse/","section":"Tags","summary":"","title":"parse"},{"content":"题目如下： 解析一个文件，\n文件格式是一行一行，\n每行有字段，字段可以加引号。\n字段里可以套字段。\n如果被嵌套的字段有引号，引号要变成双重的，表示转义，\n比如 “hello”，要变成 “…““hello””….”\n2,John,45,\u0026#34;足球,摄影\u0026#34;,New York 3,Carter Job,33,\u0026#34;\u0026#34;\u0026#34;健身\u0026#34;\u0026#34;,远足\u0026#34;,\u0026#34;河北,石家庄\u0026#34; 4,Steve,33,\u0026#34;大屏幕164\u0026#34;\u0026#34;\u0026#34;,\u0026#34;DC\u0026#34;\u0026#34;Home\u0026#34;\u0026#34;\u0026#34; 5,\u0026#34;Jul,y\u0026#34;,\u0026#34;\u0026#34;,,Canada John,33,\u0026#34;足球,摄影\u0026#34;,New York John,33,\u0026#34;足球,\u0026#34;\u0026#34;摄影\u0026#34;,New York 要解析成如下\n2 | John | 45 | 足球,摄影 | New York 3 | Carter Job | 33 | \u0026#34;健身\u0026#34;,远足 | 河北,石家庄 4 | Steve | 33 | 大屏幕164 | DC\u0026#34;Home\u0026#34; 5 | Jul,y | | | Canada John | 33 | 足球,摄影 | New York John | 33 | 足球,摄影 | New York 这个题目没啥现实意义。\n但是解答的时候却很有启发。\n看懂了题目后，第一时间我想到的是栈，\n因为嵌套结构，那么标识符号一定是成对的，所以push/pop刚好可以解决。\n管他套几层括号转义，那还不等价于一个括号对嘛。\n结果if else写了一堆，\n然后我意识到一个问题，解析的时候应该分成几层状态，\n一层是没引号的普通字段，一层是进入括号了，最后一层是进入嵌套括号了。\n写完后忽然意识到，这是个自动机，以前写算法从没写过这种。\n但是以前实现HTTP协议解析，也是这么搞的，\nnats源码里，基于CRLF的状态解析，也是这么搞的。\n其间，第一种解法，写到一半，20分钟已经过去了，可能好久没写算法了，也可能是水平不行。\n一个教训就是，通常想到一个解法，即使写到一般，发现这样不够简单优雅，也要写下去。\n不然时间不一定够。 这时候新解法的很多细节其实还没想清楚。\n以下是解答:\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) const ( CR = \u0026#34;\\r\u0026#34; LF = \u0026#34;\\n\u0026#34; ) func main() { src, err := os.Open(\u0026#34;src.txt\u0026#34;) if err != nil { panic(err) } defer src.Close() dst, err := os.Create(\u0026#34;dst.txt\u0026#34;) if err != nil { panic(err) } defer dst.Close() parseFile(src, dst) } func parseFile(r io.Reader, w io.Writer) { scanner := bufio.NewScanner(r) for scanner.Scan() { fields := parseLine(scanner.Text()) resu := strings.Join(fields, CR) fmt.Println(strings.Join(fields, \u0026#34; | \u0026#34;)) w.Write([]byte(resu)) w.Write([]byte(LF)) } if err := scanner.Err(); err != nil { fmt.Fprintln(os.Stderr, \u0026#34;读取错误:\u0026#34;, err) } } func parseLine(s string) []string { // 输出结果 rsu := []string{} // field的头指针。 start := 0 // 当前解析的状态 // -1 表示没有开始解析，或者解析结束了。 // 0 表示 这个 field 没有 `\u0026#34;` 开头 // 1 表示 这个 field 有 `\u0026#34;` 开头 // 2 表示 这个 field 处在 子field中, 类似这种: `\u0026#34;abc\u0026#34;\u0026#34;dd` status := -1 // 0 没有\u0026#34;开头， 1，有\u0026#34;开头但是不在字段中， 2. 在子field中 // 可以用 go 里的蹩脚 枚举，哈哈哈 for i := 0; i \u0026lt; len(s); i++ { switch status { case -1: if i == start { if s[i] == \u0026#39;\u0026#34;\u0026#39; { start = i + 1 status = 1 } else if s[i] == \u0026#39;,\u0026#39; { // 防止空字段。 status = -1 start = i + 1 } else { status = 0 } rsu = append(rsu, \u0026#34;\u0026#34;) } case 0: // ,xxx, if s[i] == \u0026#39;,\u0026#39; { rsu[len(rsu)-1] += s[start:i] start = i + 1 status = -1 continue } if i == len(s)-1 { rsu[len(rsu)-1] += s[start:] } if s[i] == \u0026#39;\u0026#34;\u0026#39; { // panic(\u0026#34;文件错误\u0026#34;) } case 1: // \u0026#34;xxxx\u0026#34; if s[i] == \u0026#39;\u0026#34;\u0026#39; { // \u0026#34;xxxx\u0026#34;\u0026#34; if i+1 \u0026lt; len(s) \u0026amp;\u0026amp; s[i+1] == \u0026#39;\u0026#34;\u0026#39; { status = 2 } // \u0026#34;xxxx\u0026#34;, if (i+1 \u0026lt; len(s) \u0026amp;\u0026amp; s[i+1] == \u0026#39;,\u0026#39;) || i == len(s)-1 { status = -1 } rsu[len(rsu)-1] += s[start:i] // 不管是 `\u0026#34;,` 还是 `\u0026#34;\u0026#34;` 都跳过 start = i + 2 i++ } case 2: // \u0026#34;xx\u0026#34;\u0026#34;xxx\u0026#34;\u0026#34; if s[i] == \u0026#39;\u0026#34;\u0026#39; { if i+1 \u0026lt; len(s) \u0026amp;\u0026amp; s[i+1] == \u0026#39;\u0026#34;\u0026#39; { status = 1 rsu[len(rsu)-1] += s[start-1 : i+1] } // \u0026#34;xx\u0026#34;\u0026#34;xxx\u0026#34;, if (i+1 \u0026lt; len(s) \u0026amp;\u0026amp; s[i+1] == \u0026#39;,\u0026#39;) || i == len(s)-1 { status = -1 rsu[len(rsu)-1] += s[start:i] } start = i + 2 i++ } } } return rsu } ","date":"22 October 2021","externalUrl":null,"permalink":"/contribute/parse/","section":"Code Space","summary":"解析消息，消息按逗号分割，一重引号里套两重引号表示转义","title":"有趣的算法题: 嵌套字段解析"},{"content":"","date":"15 May 2021","externalUrl":null,"permalink":"/tags/nosql/","section":"Tags","summary":"","title":"nosql"},{"content":" 分布式键值存储系统的设计与实现 # 摘 要 # 略\n关键词：键值数据库；大数据；数据分片；Raft 算法\nDistributed KV Database Design and Implementation # ABSTRACT # Section omitted\nKey words：Distributed Database; Scalable; Data Sharding; Raft Algorithm\n目 录 # 1 绪 论\n2 关键技术\n2.1 数据分片\n2.2 CAP 理论\n2.3 共识算法\n2.4 LSM 树\n3 系统设计和实现\n3.1 设计需求\n3.2 系统 API\n3.3 总体架构\n3.4 数据分片\n3.5 状态同步和持久化过程\n3.6 客户端\n3.7 调用过程\n4 总结\n4.1 学到的经验\n4.2 其他工作和可以优化的地方\n参考文献\n致 谢\n1 绪 论 # 略\n2 关键技术 # 2.1 数据分片 # 键值数据库数据分片的方法通常有根据键的范围分片和根据键的散列分片，根据键的范围分片通常给每个分片指定一块连续的键范围，然后将特定键保存到指定分片。根据键的散列分片则有助于数据的平衡分配，避免出现热点，但是也丧失了高效范围查询的能力。本文描述的系统使用了后者(据散列分片)，下文中一个分片直接称为 shard。\n2.2 CAP 理论 # 对于多副本的数据库来说，如果需要实现线性一致性，那么假如其中一部分副本节点出现网络中断，副本节点宕机之类，那么这些副本节点就不能处理请求，需要等到他们恢复才能响应，这时候可用性就会下降。对可用性较高的场景，我们可能会降低一致性要求，大多数情况下，一致性，可用性和分区容错性难以同时满足，所以需要我们做出权衡。\n2.3 共识算法 # Paxos 能够确保安全性和活性，并且支持集群成员的变更。它的正确性已被证明，并且在正常情况下是高效的。应用实现方面主要有 google 的 chubby，开源的 zookeeper，但是相对原论文做出了很多修改。不幸的是，Paxos 有两个显著的缺点。 第一个缺点是 Paxos 非常难以理解。Paxos 的第二个问题是它不能为构建实际的实现提供良好的基础。于是 Raft 算法被提出用于简化 Paxos 算法。\n根据 Raft 的论文，Raft 将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。Raft 算法被我们分成 leader 选举，日志复制，安全性和成员变更几个部分，通过不同几部分的结合，简化了算法整体的复杂性。Raft 算法的基本思想是，Raft 将客户端请求组织成一个序列，称为日志，并确保所有复制服务器看到相同的日志。每个副本按日志顺序执行客户端请求，并将其应用于服务状态的本地副本。由于所有实时副本都看到相同的日志内容，因此它们都以相同的顺序执行相同的请求，因此继续具有相同的服务状态。如果服务器失败但后来恢复，Raft 会负责更新其日志。只要至少有大多数服务器还活着，并且可以相互交谈，Raft 就会继续运行。如果没有这样的多数，Raft 将不会取得进展，但一旦多数人能够再次沟通，Raft 会尽快恢复到它中断的地方。复杂性的降低使得算法的工程实现上更易于维护。同时，Raft 和 Paxos 效率相。因此笔者选用了 Raft 算法。\n2.4 LSM 树 # LSM 的思想是对于新到来的数据直接保持在内存中，维持一个有序的结构，事实上开源实现 leveldb 使用跳表维持有序，内存中的结构被叫做 memtable，当 memtable 大小过大则会一层一层序列化成 sstable(Sorted Strings Table)到磁盘中。他们永远不会更新，只会不断向下合并，这个过程叫做 compation，从而提高写入速度，因为不存在插入操作，所以不需要 B 树那样的页分裂。相对的也引入了写放大，查询速度相对较慢等问题，作为权衡，为了解决海量数据存储的问题，在放弃 B 树高效查询的同时也可以引入布隆过滤器来提升部分整体性能，不存在的数据会被布隆过滤器过滤，只有极少量误判的数据则会被击穿到数据库中，在不同层次的 sst 中查找。\n3 系统设计和实现 # 3.1 设计需求 # 设计一个高性能的分布式 kv 数据库，支持 get/put/delete 操作。数据分布在不同的服务器上，当数据量变大时，可以通过增加服务器增加数据库的存储容量，同时分散请求到不同的服务器，以便于拆分请求负载提高性能。\n3.2 系统 API # 通过 set(key, val)设置一个键的值。通过 get(key)获取一个键的值。通过 delete(key)删除一个键。 set/get/delete 提供了强一致性，每次调用可以观察到之前所有的调用结果。计一个高性能的分布。\n3.3 总体架构 # 数据库主要由三部分构成，分别是 kv 服务器，meta 服务器和客户端。三者之间建立 TCP 连接，通过 RPC 进行通信。在我们的测试系统中，考虑到实验环境硬件和机器资源的限制，兼且 RPC 并不能体现存储系统的核心设计思想，则简单使用 golang 语言的协程(goroutine)来模拟通信，通过直接传送 golang 里的结构体实例来传送消息，也避免处理消息丢失，乱序，应用消息解包等问题。\n客户端、meta 服务器和 kv 服务器间建立连接并不会给 meta 服务器带来大量负载压力，TCP 连接是一组长连接，同时由于 meta 服务器本身并不接受请求，只负责调度分片的元信息，同时仅仅通信配置信息而不是实际的读写请求或 Shard 数据，所以 meta 服务器的负载仅仅来自于少量的 kv 服务器传送的少量数据。\n整体架构如图 3.1 所示。\n总体架构图 3.1 数据库的总体架构\n第一部分是实际存储数据的 kv 服务器，数据是被以分片(shard)的方式一段一段的存储在 kv 服务器上的，值得一提的是这里的 shard 因为采用 hash 分片的方式，所以数据是不连续的，所以 api 里没有提供 scan 接口，囿于笔者水平，在散列分片的方式下，没有想到高效的范围查询的实现方式，按照键范围分片的方式因为存储天然有序，则很容易实现 scan 查询。\nshard 本身是直接存储在 pebble 里面的，我们可以把它当做优化版的 leveldb，主要优化了多线程 compaction，多线程 flush 等。同时多个 shard 存储在同一个 pebble 引擎实例中以提高性能。\n第二部分是 meta 服务器，meta 服务器本身为了容错，使用 Raft 算法创建了 3 个副本，这样只要其中两个保持工作，系统依然能运行。meta 服务器主要存储 shard 所属的 Raft Group 和 Raft Group 与 kv 服务器之间的关系。我们实现了从 shard 的简单调度，期望数据尽可能的平均分布在不同的节点上以避免数据倾斜。当 shard 数量或者 Raft Group 发生变化的时候。shard 会自动重新平衡在不同的 Raft Group 中以重新平衡数据。\n对于每个 shard, Raft Group 和 kv 服务器之间的关系，我们封装为一个配置(一个 Config 结构体)，当 Config 发生变动时，创建一个新的配置并将它复制到 meta 服务器的其他节点中来。\nmeta 服务器也暴露了 Query(configId)接口，用于查询特定 config 下的配置中的 shard 映射。同时也方便客户端缓存 shard 和实际的 kv 服务器之间的映射，这样客户端不需要在每次 get 等请求时都访问 meta 服务器获取 shard 位置信息，提高了系统整体的请求速度。\n第三部分是客户端，用于暴露实际的 get/put/delete 接口。从宏观上看，每个查询应该首先找到分片所处的 kv 服务器组，然后通过服务器组的 Leader 通过 AppendEntry RPC 来广播数据，如果数据广播成功，Leader 可以写入数据到我们的 pepple 引擎。同时请求也可以返回。如果广播失败或大部分节点没有返回正确的响应，则不会写入或读取成功数据，读取到的数据很可能是陈旧的，对于这种情况，返回错误的响应给用户。\nkv 服务器的结构体伪代码如下：\nstruct KVServer { persister *Persister // 持久化结构体 rf *Raft // Raft 节点结构体 make_end func(string) *ClientEnd // 和其他 kv 服务器建立连接的函数，用于获取其他 kv 服务器的 shard gid int // Raft Group Id mck *metaServer.Client // meta 服务器的客户端，用于轮训获取新配置 config shardmaster.Config // 本 kv 服务器的最新配置，会写明最新应该拥有的 shard ownShards IntSet // 当前配置的拥有的 shard migratingShards HashMap\u0026lt;configId, kvpairs\u0026gt; // 配置号到需要迁移的数据的映射 waitingShards HashMap\u0026lt;shardId, gid\u0026gt; // shard 号到需要请求的 shard 的组号 cleaningShards HashMap\u0026lt;configId, shardId\u0026gt; // 需要清除的 shard 号 historyConfigs []shardmaster.Config // 历史配置的缓存 data *Storage // pebble 的封装，用于应用数据修改和持久化 cache map[int64]string // 请求缓存，防止请求重复 } 3.4 数据分片 # 本系统选择了使用通过键的散列分片的方式，这样的设计可以减少数据偏斜，防止少部分分片变成热点。考虑到通过键的范围分区的方式在产生数据偏斜的情况下需要重新分裂分片，实现更为复杂，为了简单起见，我们通过散列键来分片的方式减少数据倾斜。\n数据库获取数据分片的方式是客户端根据 shard 函数计算出自己所处的分片号，然后通过 master 获取 shard 所处的 Raft Group 的信息。通过 Raft Group 到具体 kv 服务器组的映射来获取 shard 所处的 kv 服务器。考虑每组到 kv 服务器数量通常不会超过 5 个，所以我们采用直接轮次访问的方式来尝试找到实际的 Raft Group 的 Leader 节点，可以通过缓存 Leader 节点来获得均摊查询次数为一次的优化。\n配置和 meta 服务器的结构体伪代码如下：\nstruct Config { Num int // 配置 Id Shards [NShards]int // HashMap\u0026lt;分片号, Raft Group 号\u0026gt;，因为一个分片只属于一个 Raft Group，所以用数组直接存储。Shards[0]代表 Id 为 0 的分片的 Raft Group 号 Groups map\u0026lt;Raft Group Id, []KVServer\u0026gt; // HashMap\u0026lt;Raft Group 号, kv 服务器组\u0026gt; } struct MetaServer { rf \\*raft.Raft // 使用 Raft 维持副本 configs []Config // 存储的配置序列 cache map\u0026lt;RequestId, int\u0026gt; // 请求缓存，每个请求一个 Id，防止重复写入 } 通过把分片尽可能平均分配在 Raft Group 中来平衡数据的在节点中的存储。\n3.5 状态同步和持久化过程 # 数据同步服务通过在多个复制服务器上存储其状态的完整副本来实现容错性。复制允许服务继续运行，即使其某些服务器遇到故障（崩溃或网络中断）。挑战在于，故障可能导致副本保存不同的数据副本。\n需要同步状态的有两个地方，一个是 meta 服务器的配置同步，配置是一个简单的结构体，因为数据量只有不到 1KB，所以直接通过 json 序列化保存到文件持久化，第二个是 shard 中 kv 数据操作的复制，我们的每次操作会写入日志，可以把它当做 mysql 的 binlog，我们依靠复制操作日志来实现 kv 服务器的数据同步。我们把封装的 pebble 存储引擎当做 Raft Group 里的状态机，当节点可以提交时，会写入数据到 pebble 引擎持久化数据。\nRaft 结构体伪代码如下： (省略了锁，服务器优雅关闭，其他服务器列表等对 Raft 算法本身无意义的字段以增加可读性)\nstruct Raft { persister *Persister // 持久化结构体 leaderId int // LeaerId，如果自己是 Leader,那么 id 就是自己的 id currentTerm int // 当前任期号 votedFor int // 当前任期投票给谁，对于 candidate，会投票给自己 commitIndex int // 提交号，复制到大部分节点就可以提交 lastApplied int // 应用号，提交号更新则会立刻应用到状态机 logIndex int // 最后的日志号 log []Entry // 日志序列 nextIndex []int // 作为 Leader 时，维护的其他节点的下一个日志号 matchIndex []int // 作为 Leader 时，维护的其他节点的匹配的日志号 electionTimer *Timer // 选举计时器 heartbeatTimer \\*Timer // 作为 Leader 时，心跳计时器 } 通过实现 raft 论文中描述的系统，实现了 Raft:VoteRequest, Raft:AppendEntry 和 Raft:InstallSanpshot 三个主要 RPC，其中 AppendEntry 同时用于日志广播和维持心跳阻止 follower 发起投票。\n3.6 客户端 # 客户端会通过 shard(key)函数获取键所处的分片，这是一个简单的哈希函数，然后通过缓存自 meta 服务器的配置信息找出键所处的 kv 服务器，最后直接和 kv 服务器通信，寻找 Leader，通过 Leader 提交请求需要的操作。在一致性要求不高的请求中，读操作可以访问任意一个服务器，而写操作只能写入 Leader，但是本系统都会从 Leader 读取以保证线下一致性。客户端的配置信息是初始化的时候获取的，如果某个请求读取完所有的 kv 服务器仍然没有发现 leader，客户端则会重新从 meta 服务器中获取配置信息。\n3.7 调用过程 # 3.7.1 外部请求主要过程： # 客户端操作：\n首先根据键计算出所处分片 生成 RequestId 来防止重复请求 从缓存的配置中找到 shard 所属 Raft Group，并找到 kv 服务器列表 依次请求 kv 服务器列表，尝试获取值 kv 服务器(Leader)操作： 如果不是 Leader，直接拒绝(可以通过代理请求或者返回 LeaderId 来优化) 对比 RequestId 是否重复，如果已经请求过了，阻止重复写入 根据自己的配置检查自己是否拥有该 key 的 shard 写入一个 raft 日志到日志序列(对于读请求需要写入一个空日志用于解决脑裂陈旧数据问题，下文会介绍可能的优化方法) 广播日志给 follower 节点，携带之前的日志号和日志任期号 得到大多数节点的写入回复则会提交 从 pebble 中获取该键，对于写入操作，这里需要提交应用号，但是读取操作在提交后可以直接返回值数据 3.7.2 新增或移除 Raft Group 的主要过程： (查询配置的请求基本相同) 请求 meta 服务器 对比 RequestId 是否重复，如果已经请求过了，阻止重复写入 调度 shard，以便于 shard 平均分配在 Raft Group 中，保存为新的配置 将新的配置写入 raft 的配置日志序列 广播日志给 follower 节点，携带之前的日志号和日志任期号 得到大多数 meta 节点的写入回复则会提交 更新 MetaServer 的 config 字段，标注为当前最新的配置 3.7.3 kv 服务器均衡 shard 的过程： 定时轮训 MetaServer 的配置信息，如果有新的配置信息，则更新本地的配置 如果发现配置变动，diff 自身拥有的 shard 和新配置里描述的 shard 如果 shard 不一致，将新的 shard 放到请求队列 从其他 kv 服务器(组 Leader)拉取需要的 shard，通过遍历 pebble 该 shard 里的 kv 并序列化对来打包 shard 传送(一种可能的优化方法是直接传送 sstable) 4 总结 # 4.1 学到的经验 # 对于 master/slave 结构的系统，如果我们的 master 有很多请求或者写入操作，那么他很有可能变成瓶颈，但是我们依然可以通过其他节点处理外部请求的方式实现接近于线性的伸缩性。\n散列分片的方式虽然更容易实现数据负载均衡分配，但是也可能给范围查询带来问题，需要跨多个分片合并查询，降低了系统性能。\n这些问题在系统设计的过程中多次遇到，也因此做了很多权衡，可能很多时候不是最佳的实现。\n4.2 其他工作和可以优化的地方 # 该系统的总体架构开始主要参考了 BigTable 论文实现，但是实现上与 BigTable 有很多方面的区别，第一，该系统没有采用 chubby(开源实现对应为 zookeeper)去存储关键元数据，而是采用 Raft 算法实现多个副本代替，\n第二，Tablet Server 中的 Tablet 实际上是保存在 GFS 上的 chunk，依靠 GFS 提高可用性，但是也损失了一定的性能，而我们通过 Raft Group 的方式实现 shard 的多副本机制提高可用性。\n第三，BigTable 中数据存储于 sst 中，sst 是一个排序表，对应的开源实现是 LSM 结构的 leveldb，leveldb 适用于多写少读的场景，但是写放大问题饱受诟病，pebble 可以看做是一个 go 版本的 leveldb，也是 CockroachDB 的存储引擎，它优化了 leveldb 的一些问题，考虑到存储引擎实现的复杂程度较高，笔者直接使用了该存储引擎来持久化数据。\n最后，考虑到工作量也并没有能实现 BigTable 里描述的多版本的数据存储，因此数据模型只有两个维度，也不需要考虑版本的垃圾回收。\n该数据库尚有很多可以优化的地方，对于客户端查询，可以尝试缓存 Leader 信息，客户端每次查询特定 Raft Group 的时候，通过轮次查询获得特定的 Group 的 Leader 节点信息，此时缓存 Leader 节点信息，因为 Leader 一般不会不断更新，所以可以每次客户端查询的均摊次数可以接近一次。\n根据 Raft 算法论文客户端部分的描述，可以实现基于租约的方式来阻止脑裂下的陈旧数据问题，这样可以提高整体的性能，目前的做法是将读类型的请求写入 log 通过 Raft 提交，提交之后一定能获取最新的数据，这样每次读起码需要获取过半节点中最慢节点的一次请求响应延迟。这样的解决方法虽然可以实现线性一致性，但是性能不佳。一种可能的更简单的优化方法是广播一个空 RPC 来确认自己仍然是 Leader，这样可以避免提交和存储到日志这些不必要的操作。\n使用基于范围的分片可以实现高效的范围查询，同时也可以在分片过大的时候动态的分裂分片，本系统里只是简单的配置固定数量的分片，如果按照键范围分片则需要动态分割分片。然后依靠已经实现的 meta 服务器调度，将新分片转移到其他 Raft Group。\n最后可以实现一些简单的监控系统，以收集分片，每秒接受的 RPC 数量，Leader 转移的次数等信息，便于更好的了解系统运行状态。\n参考文献 # (忽略了一些毫无价值，受某些因素影响放上去的论文 :)\n[1] Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C. Hsieh, Deborah A. Wallach, Michael Burrows, Tushar Chandra, Andrew Fikes, Robert Gruber: Bigtable: A Distributed Storage System for Structured Data[J]. OSDI 2006:205-218.\n[2] Diego Ongaro and John Ousterhout Stanford University. In Search of an Understandable Consensus Algorithm (Extended Version)[J]. 2013．\n[3] 陈陆. 分布式键值存储引擎的研究与实现[D]. 江苏科技大学，2016.\n[4] 赵江. 基于 LevelDB 的分布式数据库的研究与实现[D].国防科学技术大学，2019.\n[5] .\n[6] .\n[7] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung Google. The Google File System[J]. 2003.\n[8] VoltDB. VoltDB Resources[OL].2012.\n[9] Patrick Hunt and Mahadev Konar Yahoo! Grid, Flavio P. Junqueira and Benjamin Reed Yahoo! Research. ZooKeeper: Wait-free coordination for Internet-scale systems[J]. 2005.\n[10] .\n[11] .\n[12] 涂腾飞. Go 语言中的并发问题研究[D].北京邮电大学，2019.\n[13] .\n致谢 # 略\n","date":"15 May 2021","externalUrl":null,"permalink":"/paper/kvstore/","section":"Papers","summary":"键值数据库数据分片的方法通常有根据键的范围分片和根据键的散列分片，根据键的范围分片通常给每个分片指定一块连续的键范围，然后将特定键保存到指定分片。根据键的散列分片则有助于数据的平衡分配，避免出现热点，但是也丧失了高效范围查询的能力。","title":"分布式键值存储系统的设计与实现"},{"content":"","date":"14 May 2021","externalUrl":null,"permalink":"/tags/about/","section":"Tags","summary":"","title":"about"},{"content":"","date":"14 May 2021","externalUrl":null,"permalink":"/tags/culture/","section":"Tags","summary":"","title":"culture"},{"content":"","date":"14 May 2021","externalUrl":null,"permalink":"/tags/japanese/","section":"Tags","summary":"","title":"japanese"},{"content":"","date":"14 May 2021","externalUrl":null,"permalink":"/tags/name/","section":"Tags","summary":"","title":"name"},{"content":"","date":"14 May 2021","externalUrl":null,"permalink":"/tags/story/","section":"Tags","summary":"","title":"story"},{"content":" 原文开头:\n这几天日本改年号令和说选自万叶集，也想蹭蹭日本人的雅致，第一篇就叫樱之章，取自万叶恋歌的第一章。 万叶集里有一首雷神短歌，\n隐约雷鸣，阴霾天空，但盼风雨来,能留你在此。\n若是觉得有趣，不妨搜索下一句，对比诗经天地合乃敢与君绝，仿佛失去了那种至死不渝的气势，到是多了几分初见的青涩，倘若让我选，或是前者，昙花一刹，胜过万千。\n关于 艾风逸 # 十多年前年前我就使用艾风逸作为网名，其实他是我想给自己取得名字。我一直觉得父亲取名时迷信鬼神占卜，肤浅幼稚，故而对自己的名字颇为不满。\n风逸的风是指虚无缥缈，存在却又无形的，看不见无处不在却容易被忽略的东西。代指自然规律，又像社会规则这样的看不见的东西。\n小时候我总觉着，大家一直埋头学习，为什么不重新审视一下是否该学习，又该如何学习，该学什么。大家一直学，却从没想过如何学，为何学，所以学习就是一阵风，空气一样无处不在，却没人注意他。\n逸是指灵动跳脱，寓意能看清一切，从而随心所欲。换个说法，想赚钱就能赚到钱，想学啥就能学会，高效学习是自然规律，了解记忆曲线，题海都是对人脑学习规律的理解，赚钱则是对人类世界规则的理解，看很多人利用关系也好，利用资本也罢，都是对看不见的赚钱规则的正确认识。当然这些都只是自己的幻想，因为是名字嘛，所以总有点期望的意思，就像王百万一样。\n有些不知道的，可能会觉着这个名字挺文艺的，其实本人的寓意是这么个意思。\n有意思的是，我曾遇到一个女孩子用水若做名字，可那个女孩子太漂亮，那个年纪也没敢聊两句，想来聊多了又觉得你和她格格不入也没意思就是了。\n这是是我初中时取得昵称。一直用所以挺有感情。我很喜欢这个名字，我是个思想比较开放、自由和激进的人，所以以前，我想以后和谁结婚了，这个名字可以给孩子，如果妈妈喜欢，就随她姓把艾去掉。当然到高中开始已经决定以后不要孩子了。\n十多年过去，物是人非，房子被拆迁了搬走了，小伙伴因为教育分流也不联系了，只有这昵称，却一直被我保留着。\n注:\n原文发布在简书(2019-04-08T21:07:05+0800)，因为麻烦的审核机制已经放弃简书了。后迁到博客，因为所有数据丢失了，博客源码和文章也没有了，从其他网站移植过来。\ncover 上的 summary 是后来补充的。 ","date":"14 May 2021","externalUrl":null,"permalink":"/inspiration/name/","section":"Grocery","summary":"每个人大概都一定程度上不喜欢自己的出身，名字，历史，那些不能掌控的初值。小时候一直想给自己取个新名字，是一种抱怨，无能的人才会抱怨，表达对既定的不满又无力改变；也是一种期盼，包含对的美好祝福。","title":"艾风逸: 名字的故事"},{"content":"","date":"12 May 2021","externalUrl":null,"permalink":"/series/asia-culture/","section":"Series","summary":"","title":"Asia Culture"},{"content":" The original name of this poem is \u0026ldquo;虞美人·听雨\u0026rdquo;.\nRain Watcher # Listen to the rain in the party when I’m young. I can see the light of red candles reflected from curtain cover.\nListen to the rain in a floating boat when I’m an adult. I can see the wild goose fly against the west wind between board river and low cloudy sky.\nBut now I listen to the rain under the eaves of a temple, my hair has partly turned white. God seems has no emotion about our sadness and happiness, leave or reunion. I hear it rains from dusk to dawn, one drop by another.\nModern Version # When I’m young, I enjoy the party, the indulging atmosphere drives me crazy.\nWhen I’m an adult, I leave my hometown to find better oppotunity, I have ambition when I’m on the way to bright future.\nNow that I have experienced too much, I sit in a temple and care nothing about outside world.\n","date":"12 May 2021","externalUrl":null,"permalink":"/inspiration/rain/","section":"Grocery","summary":"I hear it rains from dusk to dawn, one drop by another.","title":"Asian Poem: Rain Watcher"},{"content":"","date":"12 May 2021","externalUrl":null,"permalink":"/tags/poem/","section":"Tags","summary":"","title":"poem"},{"content":"","date":"12 May 2021","externalUrl":null,"permalink":"/tags/ddia/","section":"Tags","summary":"","title":"ddia"},{"content":" 分布式系统考虑的要点： # 可扩展/高可用即 多个节点 失败优先，假设所有节点都会失败，默认会失败，这样就必须考虑某个节点失败了如何处理，由此衍生出所谓单点问题，keepalive 等 网络不可靠，比如请求失败. CAP：复制节点的一致性问题,可用还是强一致？ 第一部分：基础 # 可靠性、可扩展等: 可以稍微看一下几个指标，其中有个 twitter 扇读的例子。 模型和查询语言: 讲述了 sql 语言和 mapreduce，关系型和非关系型 存储和检索: 讲述 b 树和 lsm 树，强烈建议多次重读，又读过一遍后:超级建议反复读，讲了存储模型 b 和 lsm，也讲了行存和列存，列存不等于列族存，比如 bigtable，同时也讲了聚集索引就是索引上直接存数据，也讲了为什么 OLTP 和 OLAP 不同，同时为什么列存更适合用于分析。 编码和演化：比较了 json 和二进制编码 protobuf, thrift, avro 等编码方式和 grpc 等 rpc 第二部分: 数据分布 # 复制 复制原来干嘛的： 容错(防止丢数据)，扩展性(3 台机器抗压力)，降低延迟(复制副本到离用户近的地方，比如微信朋友圈在三地三副本，就近处理请求) 复制算法分类： 无领导者，单领导者，多领导者 单领导者/主从复制： 热备就是一个简单的从。举例：mysql, pg, mongodb, kafka, rabbitMQ, bigtable 同步/异步/半同步： 同步就是所有写入时写入成功所有节点才返回，半同步就是写入一个从和自己成功即返回… 异步超简单主库写入成功就返回，就当从库不存在 从库进度缓慢/新增从库： 通过 snapshot+replication log 的 id 来同步，举例: mysql innobackupex+binlog coordinates，日志号在 pg 中叫 LSN 崩溃和宕机： 从宕机-\u0026gt;追赶进度。 主宕机-\u0026gt;故障转移，所谓故障转移是指重新选主，然后客户端更新主路由，从同步新主数据的过程 脑裂： 上述的新主出现了，如果老主节点网络恢复了，那么就可可能出现两个主机同时接受写入。。。因为不是所有主都是 raft 那样被大部分节点投票产生的. 复制日志的实现： 可以理解成 raft 日志的形式，通常有三种，一种基于语句，基于语句因为并发事务和非确定性函数(比如 now)而很少用 mysql5 以前使用，另一种基于行，即新增增加了哪几行？统一存入日志，即包含一行或几行的详细信息，同时多行被封装成一个事务。这种方式好的地方是，外部数据源也可以解析数据，他是一行的实际信息，并不是字节改动或语句 WAL 原理和使用场景：最后一种复制 WAL，原理每次写都会写到一个仅 append 日志，日志包含磁盘里哪些字节变化了而不是实际语句，场景是 LSM 的存储方案，另一个是大部分 RDB 数据库写入，或者 B 树分裂。对于复制日志，会在网络上传输 WAL，通常不同版本 db 有不同的 WAL 结构，导致需要宕机升级数据库 手动复制: 触发器，比如需要数据变更的一个子集。 分区 事务 分布式系统的问题 一致性问题 第三部分：衍生数据 # 所谓衍生数据是指 不是处理用户实时请求的数据， 比如 kafka 作为数据连接器将数据从 mysql 同步到 es，又或者 mq 削峰,\n在本书中这类被称作流处理 比如大多数定时任务，汇集赞的定时任务，推荐系统(计算每个人的推荐 items 然后写入 hbase)就是批处理，简单点我们可以把批处理当成定时任务，流处理当成队列处理\n批处理 流处理 未来 ","date":"12 May 2021","externalUrl":null,"permalink":"/contribute/ddia/","section":"Code Space","summary":"一本讲数据系统的很好的书，CRUD 时可以多翻翻，这里梳理了重点","title":"DDIA 读书笔记"},{"content":"","date":"12 May 2021","externalUrl":null,"permalink":"/tags/system-design/","section":"Tags","summary":"","title":"system design"},{"content":"","date":"23 April 2021","externalUrl":null,"permalink":"/tags/editor/","section":"Tags","summary":"","title":"editor"},{"content":"","date":"23 April 2021","externalUrl":null,"permalink":"/tags/vim/","section":"Tags","summary":"","title":"vim"},{"content":" vim 是什么 # vim 是一种编辑方式，编辑唯一的要求是定位光标，比如调到某函数，修改该函数的参数。\nvim 本身也可以打造出 IDE，但 vim 不应该是 IDE。\n为什么用或不用 vim? # 优点： 输入高效，其实熟练以后不用动脑子，就是肌肉记忆。想象一下，小时候和朋友 QQ 聊天时有什么负担吗？没有，我们打字打得飞起，就那种感觉，vim 习惯后和 QQ 打字并没有任何区别。那么为什么我们熟悉了 QQ 打字还有学 vim 呢，vim 可以用来移动光标，比如移动到一个论文的第二章，或者，移动到一个函数的函数名，或者删除括号里的参数。\n缺点： vim 作为编辑器本身并不亲民，轻量但是功能不强(和其他编辑器比较)，比如很多 java 做开发的会直接点击运行，然后程序就跑出来了，然后 vim 里你要写个脚本，或者安装一些插件，学习下怎么用(通常也要命令…)，*nux 下的开发者往往更喜欢这样。然后往往会用其他编辑器都开 vim 模式，但是其他编辑器 vim 模式不见得好用。\n另外，chrome 等也有 vim 模式，熟悉以后也很好用，有时候会鼠标点点，有时候想起来又直接 j 上下滑，/来搜索，f 来跳连接，没有任何负担。\n这里有个误解，vim 补全提示什么的不太行，其实大部分编辑器都是用的一样的插件，原理是使用了 LSP 这种协议，编辑器前端根本不解析语言只负责查询，比如询问 language server 输入 math. 后面应该补全啥，\n区别是 vim 默认没有支持，需要你花 2 分钟输入命令安装一下，不像其他一些编辑器开箱即用。\n快捷键实例 # 复制所有内容到系统剪切板 主要因为行号，所以不能手动 ctrl+c，gg\u0026quot;+yG，解释：ggyG或ggvGy是复制所有，\u0026quot;+y是复制到系统剪切板，因为+和*是系统 buffer. 快速跳到字母 按 f\n关于远程开发 # 远程开发时，vim 插件要运行与远程服务器。\n我的本地的 vimrc # syntax on set termguicolors filetype plugin indent on set nu \u0026#34;显示行号 set relativenumber set showcmd \u0026#34;显示命令 set showmatch \u0026#34;显示匹配括号 set cindent \u0026#34;c/c++分格缩进 set backspace=indent,eol,start set hidden \u0026#34;退出不会提示，buffer has not changed... set nowrap \u0026#34;split的窗口，这边编辑的字符不会顶出到别的窗口 set shell=/bin/sh \u0026#34; 解决coc安装问题 \u0026#34;所有类型tab都转换为4字符 set expandtab set smarttab set shiftwidth=4 set tabstop=4 set history=9999 \u0026#34;vim记住历史操作次数, 重度使用的时候4k几天就搞没了，， set autoread \u0026#34;当文件在外部被修改时，自动重新读取 set hlsearch \u0026#34;高亮度反白 set laststatus=2 \u0026#34;显示当前编辑文件的文件名和路径 set encoding=utf-8 \u0026#34; 。。。 set cursorline imap jk \u0026lt;ESC\u0026gt; 我的开发环境 vimrc # 如果要使用 vim 做开发，那么应该配置在远程服务器上，\n(自己的项目可以在阿里云上买个服务器)\n然后通过 ssh + tmux 连上，运行 vim 命令就有效果了。\n既然本地没有开发环境，那么本地 vim 也就同样不需要开发插件了，\n顶多开个 markdown 或者基本高亮。\nsyntax on set termguicolors filetype plugin indent on set nu \u0026#34;显示行号 set relativenumber set showcmd \u0026#34;显示命令 set showmatch \u0026#34;显示匹配括号 set cindent \u0026#34;c/c++分格缩进 set backspace=indent,eol,start set hidden \u0026#34;退出不会提示，buffer has not changed... set nowrap \u0026#34;split的窗口，这边编辑的字符不会顶出到别的窗口 set shell=/bin/sh \u0026#34; 解决coc安装问题 \u0026#34; set t_Co=256 \u0026#34;所有类型tab都转换为4字符 set expandtab set smarttab set shiftwidth=4 set tabstop=4 set history=9999 \u0026#34;vim记住历史操作次数, 重度使用的时候4k几天就搞没了，， set autoread \u0026#34;当文件在外部被修改时，自动重新读取 set hlsearch \u0026#34;高亮度反白 set laststatus=2 \u0026#34;显示当前编辑文件的文件名和路径 set encoding=utf-8 \u0026#34; 。。。 \u0026#34;color desert set cursorline \u0026#34;hi CursorLine term=bold cterm=bold guibg=Grey40 \u0026#34;hi CursorLine cterm=NONE ctermbg=darkred ctermfg=white \u0026#34; auto complete } and enter next line inoremap {\u0026lt;CR\u0026gt; {\u0026lt;CR\u0026gt;}\u0026lt;ESC\u0026gt;O imap jk \u0026lt;ESC\u0026gt; let g:dracula_italic = 0 \u0026#34; let g:embark_terminal_italics = 0 \u0026#34;remember last edit autocmd BufReadPost * \\if line(\u0026#34;\u0026#39;\\\u0026#34;\u0026#34;)\u0026gt;0\u0026amp;\u0026amp;line(\u0026#34;\u0026#39;\\\u0026#34;\u0026#34;)\u0026lt;=line(\u0026#34;$\u0026#34;)| \\exe \u0026#34;normal g\u0026#39;\\\u0026#34;\u0026#34; | \\endif call plug#begin(\u0026#39;~/.vim/plugged\u0026#39;) \u0026#34; 状态栏 哟西 Plug \u0026#39;vim-airline/vim-airline\u0026#39; Plug \u0026#39;vim-airline/vim-airline-themes\u0026#39; Plug \u0026#39;takac/vim-hardtime\u0026#39; \u0026#34; 主题 Plug \u0026#39;arcticicestudio/nord-vim\u0026#39; Plug \u0026#39;jaredgorski/spacecamp\u0026#39; Plug \u0026#39;dracula/vim\u0026#39;, { \u0026#39;as\u0026#39;: \u0026#39;dracula\u0026#39; } Plug \u0026#39;embark-theme/vim\u0026#39;, { \u0026#39;as\u0026#39;: \u0026#39;embark\u0026#39; } Plug \u0026#39;morhetz/gruvbox\u0026#39; Plug \u0026#39;fatih/vim-go\u0026#39;, { \u0026#39;do\u0026#39;: \u0026#39;:GoUpdateBinaries\u0026#39; } \u0026#34; go 插件 跳转函数定义， ctrl+o 返回, ctrl+i再次进入 Plug \u0026#39;https://github.com/joshdick/onedark.vim.git\u0026#39; \u0026#34; 目前最喜欢da。。 \u0026#34; Plug \u0026#39;luochen1990/rainbow\u0026#39; \u0026#34; 彩虹括号嘿嘿嘿 Plug \u0026#39;tpope/vim-surround\u0026#39; \u0026#34; ci\u0026#39; Plug \u0026#39;tpope/vim-commentary\u0026#39; \u0026#34; gcc \u0026#34; Plug \u0026#39;prettier/vim-prettier\u0026#39;, { \u0026#39;do\u0026#39;: \u0026#39;yarn install\u0026#39; } Plug \u0026#39;preservim/nerdtree\u0026#39; Plug \u0026#39;mhinz/vim-startify\u0026#39; Plug \u0026#39;Yggdroot/indentLine\u0026#39; Plug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} \u0026#34; 哟西 \u0026#34; Plug \u0026#39;tweekmonster/gofmt.vim\u0026#39; \u0026#34; :w 格式化... Plug \u0026#39;tpope/vim-fugitive\u0026#39; \u0026#34; :Git status, git支持... Plug \u0026#39;vim-utils/vim-man\u0026#39; \u0026#34; man vim... Plug \u0026#39;mbbill/undotree\u0026#39; \u0026#34; UndotreeToggle 来切换，选择+回车 = 跳到那个undo Plug \u0026#39;sheerun/vim-polyglot\u0026#39; \u0026#34; 扩展语言包， 支持小众语言高亮 Plug \u0026#39;junegunn/fzf\u0026#39;, { \u0026#39;do\u0026#39;: { -\u0026gt; fzf#install() } } Plug \u0026#39;junegunn/fzf.vim\u0026#39; Plug \u0026#39;stsewd/fzf-checkout.vim\u0026#39; \u0026#34; Plug \u0026#39;tpope/vim-dispatch\u0026#39; \u0026#34; 通过 :Dispatch! xx 命令在vim内运行cmd \u0026#34; Plug \u0026#39;rust-lang/rust.vim\u0026#39; \u0026#34; rust插件 call plug#end() \u0026#34; 使用Tab进行补全 inoremap \u0026lt;silent\u0026gt;\u0026lt;expr\u0026gt; \u0026lt;TAB\u0026gt; \\ pumvisible() ? coc#_select_confirm() : \\ coc#expandableOrJumpable() ? \u0026#34;\\\u0026lt;C-r\u0026gt;=coc#rpc#request(\u0026#39;doKeymap\u0026#39;, [\u0026#39;snippets-expand-jump\u0026#39;,\u0026#39;\u0026#39;])\\\u0026lt;CR\u0026gt;\u0026#34; : \\ \u0026lt;SID\u0026gt;check_back_space() ? \u0026#34;\\\u0026lt;TAB\u0026gt;\u0026#34; : \\ coc#refresh() function! s:check_back_space() abort let col = col(\u0026#39;.\u0026#39;) - 1 return !col || getline(\u0026#39;.\u0026#39;)[col - 1] =~# \u0026#39;\\s\u0026#39; endfunction let mapleader=\u0026#39;,\u0026#39; let g:mapleader=\u0026#39;,\u0026#39; nnoremap \u0026lt;silent\u0026gt; \u0026lt;C-p\u0026gt; :Files\u0026lt;CR\u0026gt; nnoremap \u0026lt;silent\u0026gt; \u0026lt;C-k\u0026gt; :Buffers\u0026lt;CR\u0026gt; nmap ,v :NERDTreeToggle\u0026lt;CR\u0026gt; nmap ,g :NERDTreeFind\u0026lt;CR\u0026gt; let g:coc_snippet_next = \u0026#39;\u0026lt;tab\u0026gt;\u0026#39; let g:coc_global_extensions = [ \\ \u0026#39;coc-tsserver\u0026#39; \\ ] \u0026#34; 设置 上面的状态栏插件的主题 let g:airline_theme=\u0026#39;luna\u0026#39; \u0026#34; let g:rainbow_active = 1 \u0026#34; 打开彩虹括号 \u0026#34; let g:indentLine_setColors = 0 \u0026#34; colorscheme spacecamp colorscheme onedark \u0026#34;mio \u0026#34; colorscheme nord \u0026#34; colorscheme embark \u0026#34; colorscheme dracula \u0026#34; colorscheme gruvbox \u0026#34; set background=dark \u0026#34; hard time ! let g:hardtime_default_on = 0 \u0026#34; let g:gruvbox_contrast_dark = \u0026#39;medium\u0026#39; \u0026#34; highlight Pmenu ctermbg=238 gui=bold viminfo 命令历史 # 以下这些命令，是直接复制的 history 命令\nvs l/solution.go sp l/solution.go !go test -timeout=3s -v c114/* %s/TreeNode/Node/g # 替换 %s/\\]/\\}/g # 替换括号 %s/existWord/checkExist/g !python3 inits.py 216 resize +10 CocInstall coc-json coc-tsserver CocInstall coc-tsserver coc-html coc-css Prettier !go run % | more PlugInstall PlugUpgrade CocConfig !g++ client4.cc -o client !node % CocInstall coc-clangd coc-rls CocConfig # { \u0026#34;coc.preferences.formatOnSaveFiletypes\u0026#34;: [ \u0026#34;javascript\u0026#34;, \u0026#34;javascriptreact\u0026#34;, \u0026#34;typescript\u0026#34;, \u0026#34;typescriptreact\u0026#34; ], \u0026#34;tsserver.formatOnType\u0026#34;: true, \u0026#34;coc.preferences.formatOnType\u0026#34;: true, \u0026#34;clangd.path\u0026#34;: \u0026#34;/Users/challenai/.config/coc/extensions/coc-clangd-data/install/11.0.0/clangd_11.0.0/bin/clangd\u0026#34; } 插件列表 # - Finishing ... Done! - vim-polyglot: Already installed - indentLine: Already installed - vim-startify: Already installed - fzf: Already installed - fzf.vim: Already installed - nord-vim: Already installed - coc.nvim: Already installed - vim-commentary: Already installed - vim-hardtime: Already installed - nerdtree: Already installed - embark: Already installed - gruvbox: Already installed - vim-fugitive: Already installed - vim-airline-themes: Already installed - vim-surround: Already installed - vim-man: Already installed - dracula: Already installed - vim-go: Already installed - onedark.vim: Already installed - vim-airline: Already installed - fzf-checkout.vim: Already installed - undotree: Already installed - spacecamp: Already installed 2024-Mar-20 补充: 强烈推荐使用 neovim，可以减少配置，\n但是某些云上机器，不想安装任何插件，可以直接复制第一个 vimrc\n个人的习惯是：\nJava 用 jetbrains 编辑器家族\n前端用 vscode\nGo 和 C++ 用 vim\n最近用 vscode 比较多，特点是打开很快，升级和插件都很方便，有时候懒得换，\n维护升级多个编辑器比较麻烦，所以甚至写 Java 也直接一股脑用他了。\n(仅供参考，不喜勿喷)\n","date":"23 April 2021","externalUrl":null,"permalink":"/contribute/vim/","section":"Code Space","summary":"vim 是一种编辑方式，编辑唯一的要求是定位光标，比如调到某函数，修改该函数的参数","title":"Vim 及其配置"},{"content":"","date":"23 April 2021","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"docker"},{"content":" 新创建 Docker 工作流: # 编写 Dockerfile 构建新镜像 build 运行 run 停止 stop 删除 rm 构建新镜像 # docker build -t statusbarimg . 启动容器 # -d 后台， -p 暴露给外部的(宿主):内部监听的端口(容器) –name 别名\ndocker run --name statusbarcontainer -d -p 80:8000 statusbarimg 交互模式启动 # docker run -it --name statusbarcontainer -p 80:8000 statusbarimg 启动/停止/重启 # docker start/stop/restart statusbarcontainer/container_id 删除容器 # docker rm statusbarcontainer 删除镜像 # docker rmi 连接容器 # link db:db 连接到名为 db 的 容器上，并且用 db 指代该容器 -e DATABASE_HOST=db 将环境变量 DATABASE_HOST 设置为 db\ndocker run -it -p 8123:8123 --link db:db -e DATABASE_HOST=DB users-service 在 xx 容器中执行命令 # docker exec statusbarimg cat /etc/hosts 关闭 # docker kill container_id 查看容器 # docker ps # -l(最近一次运行的)/-a(所有的) 查看镜像 # 注意，运行着或运行过的镜像为容器，删镜像要先删容器，包括运行过的, 流： ps -a 看容器 id -\u0026gt; rm 删容器 -\u0026gt; images 看镜像 -\u0026gt; 删镜像\ndocker images 拉取/推送/搜索 # docker pull/push/search tag # docker tag 195eb90b5349 seanlook/ubuntu:rm_test 提交对 image 的改动 # 对运行中的容器编辑后，可以保存修改，持久化到磁盘\ndocker commit -m \u0026#34;some tools installed\u0026#34; fcbd0a5348ca seanlook/ubuntu:14.10_tutorial 进入正在后台运行的容器后 exit 会导致容器关闭) # docker exec -it 6057024435c4 /bin/sh 其他参考:http://blog.csdn.net/permike/article/details/51879578\n复制文件到容器 # docker cp ./peatio cf152a690090:/root .Dockerfile 示例\n# 设置基础镜像 和 维护者 FROM daocloud.io/node:8 MAINTAINER me@yanbingbing.com # 设置env环境 ENV HTTP_PORT 8000 # 设置工作目录 和 复制本地镜像到容器中 COPY . /app WORKDIR /app npm install RUN npm install --registry=https://registry.npm.taobao.org # 暴露的端口 EXPOSE 8000 # 命令 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] Docker Composer # Docker Composer 允许用户创建一个文件，在其中定义系统里的每个容器，容器间的关系，并且构建或者运行它们。\n就是一下子跑数据库，app 和 nginx,并排好他们的连接关系，启动顺序，自动执行\nDocker Composer 工作流 # 写 docker-compose.yml -\u0026gt; build -\u0026gt; up -\u0026gt; down\ndocker-compose build docker-compose up/down Docker 网络互联 # docker run 里的–network 选项有 bridge,host,自定义的名字等 同一个 network 下面可以互联，默认是 bridge，自定义的名字就像一个 namespace 一样，可以直接相互连接。\n比如，在 connected 这个网络空间中，运行容器\ndocker run -d -p 3001:3001 --network connected --name post post ","date":"23 April 2021","externalUrl":null,"permalink":"/contribute/docker/","section":"Code Space","summary":"Docker 构建和测试镜像工作流: 编写 Dockerfile -\u0026gt; 构建新镜像 build -\u0026gt; run -\u0026gt; stop -\u0026gt; rm","title":"Docker 命令速查"},{"content":"","date":"22 April 2021","externalUrl":null,"permalink":"/tags/https/","section":"Tags","summary":"","title":"HTTPS"},{"content":" HTTPS/SSL/TLS # 需要使用加密的http连接，就需要证书和私钥 私钥服务器持有，证书(公钥)分发出去 然后公钥加密对称加密的秘钥(生成的一串随机数) 最后双方通信使用对称加密。两边都持有对称加密的秘钥\nhttps证书生成： # 1、生成RSA密钥的方法 openssl genrsa -des3 -out key.pem 2048 这个命令会生成一个2048位的密钥，同时有一个des3方法加密的密码，如果你不想要每次都输入密码，可以改成： openssl genrsa -out key.pem 2048 建议用2048位密钥，少于此可能会不安全或很快将不安全。\n2、生成一个证书请求\nopenssl req -new -key key.pem -out cert.csr\n这个命令将会生成一个证书请求，当然，用到了前面生成的密钥key.pem文件\n这里将生成一个新的文件cert.csr，即一个证书请求文件，你可以拿着这个文件去数字证书颁发机构（即CA）申请一个数字证书。CA会给你一个新的文件cert.pem，那才是你的数字证书。\n如果是自己做测试，那么证书的申请机构和颁发机构都是自己。就可以用下面这个命令来生成证书：\nopenssl req -new -x509 -key key.pem -out cert.pem -days 1095 这个命令将用上面生成的密钥key.pem生成一个数字证书cert.pem\n3、使用数字证书和密钥\n有了key.pem和cert.pem文件后就可以在自己的程序中使用了，比如做一个加密通讯的服务器\n上述是讲解的详情，如果我们要生成私钥用于测试本地https(该命令来自nodejs文档https部分):\nopenssl req -x509 -newkey rsa:2048 -nodes -sha256 -subj \u0026#39;/CN=localhost\u0026#39; \\ -keyout key.pem -out cert.pem 然后将cert.pem(公钥)，key.pem(私钥)放到index.js或nginx.conf目录即可：\nconst http2 = require(\u0026#39;http2\u0026#39;); const fs = require(\u0026#39;fs\u0026#39;); const server = http2.createSecureServer({ key: fs.readFileSync(\u0026#39;key.pem\u0026#39;), cert: fs.readFileSync(\u0026#39;cert.pem\u0026#39;) }); server.on(\u0026#39;error\u0026#39;, (err) =\u0026gt; console.error(err)); server.on(\u0026#39;stream\u0026#39;, (stream, headers) =\u0026gt; { // 流是一个双工流。 stream.respond({ \u0026#39;content-type\u0026#39;: \u0026#39;text/html; charset=utf-8\u0026#39;, \u0026#39;:status\u0026#39;: 200 }); stream.end(\u0026#39;\u0026lt;h1\u0026gt;你好世界\u0026lt;/h1\u0026gt;\u0026#39;); }); server.listen(8443); 对于nginx.conf，这里以http2为例，因为http2强制使用https:\n值得一提的是http2依然可以proxy到http1.1的服务器\n(因为http2解决了队头阻塞问题和二进制传输，所以只要客户端和网关间建立http2连接即可,不必内部完全是http2,nginx暂时持有http2 frame，最后组成http文本头传给服务器)\nserver { listen 443 ssl http2; server_name hostname.com; ssl_certificate cert/cert.pem; ssl_certificate_key cert/key.pem; location / { proxy_pass http://localhost:12345; } } chrome不受信任的连接问题 # 根据TLS(安全传输层)原理，客户端必须有证书。\nmac系统里，打开钥匙链app(keychain access)，然后file-\u0026gt;import item来导入cert.pem\n导入后，双击该证书，设置信任该证书。\n然后访问https://localhost即可。\n","date":"22 April 2021","externalUrl":null,"permalink":"/contribute/https/","section":"Code Space","summary":"HTTPS 证书申请，编码调用证书和 nginx 配置","title":"HTTPS/SSL/TLS"},{"content":"","date":"22 April 2021","externalUrl":null,"permalink":"/tags/ssl/","section":"Tags","summary":"","title":"SSL"},{"content":"","date":"22 April 2021","externalUrl":null,"permalink":"/tags/tls/","section":"Tags","summary":"","title":"TLS"},{"content":" The poem are selected from the Book of Poetry which is written in about 500~550 A.D.\nThe original name is \u0026ldquo;诗经：氓\u0026rdquo;.\nChapter One # A man looks attractive comes to me,\nswap my silk with his cloth.\nBut he doesn’t want the silk,\nhe wants me.\nI’m about to accompany with him to the River Qi when he leave,\nbut I keep going until Hill Dunqu.\nI don’t want to delay our marriage inside my heart,\nbut you(the man) never make a formal propose.\nPlease don’t be angry,\nI promise you autumn is our time.\nChapter Two # I miss you so sick,\nI stand in the city wall to look for you,\nI can feel my smile so bright when I find you,\nI can also feel my pain if you don’t appear.\nYou ask for fortune-teller to divine our future, It’s bright,\nso I enter your carriage and get married without doubt.\nChapter Three # When the leaf of mulberry tree hasn’t withered,\nit looks colorful.\n(When I’m still young, I looks beautiful.)\nTurtledove, don’t eat too much mulberry fruit.\nGirl, don’t fall too deep in love.\n(Chinese myth says the turtledove will get poisoning when it eat too much mulberry fruit, perhaps the girl should not fall in love too quickly, it\u0026rsquo;s the poison)\nIf a man fall in love, he can still leave,\nif a woman fall in love, she will get trapped.\n(In the traditional Chinese society, if a woman has married with someone, she is hard to remarry with someone else when divorced, the situation of man is totally different)\nChapter Four # Now the leafs of mulberry has withered,\nthey fall down from the limb.\nSince I came to your family,\nmy life became poor.\nRiver Qi runs day and night,\nit wets the curtain of my carriage (I decide to leave you).\nI have no fault in my behavior,\nbut you are inconsistent.\nChapter Five # After I become your wife, I work hard for our family;\nI sleep late, I wake up early.\n(however, we often have conflicts.)\nSince the verbally abusive ends,\nthe violence starts.\nBrothers are not wise enough,\nlaugh loudly at me.\nI stay alone and calm down to consider about myself,\nhow sad I am!\nChapter Six # River Qi looks so board, but it still has its border.\nSwamp Xi looks so large, but is also has its end.\n(so does our love.)\nI remind of my warm family time,\nwhen I was a little girl.\nEven though once we own the swear and promise from each other,\nwe are apart now,\nI will never think about our experience again,\nit’s end.\nOriginally post in medium (2020-10-27T13:17:05) and modified some sentences, link attached as follow: A love story from distant eastern world\n","date":"27 October 2020","externalUrl":null,"permalink":"/inspiration/meng/","section":"Grocery","summary":"Love is always the topic for us all. It repeats again and again during thousands of years of our journey. It\u0026rsquo;s simple like that, fall in love, together and apart. maybe happy, maybe painful, kinda experience.","title":"Asian Poem from 1500 Years Ago: An Attractive Man"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]